#!/usr/bin/env python3
# progress_ui_advanced.py - UI Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø³Ø±Ø¹Øª Ùˆ Ù¾ÛŒØ´Ø±ÙØª Ø¨Ø§ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ

from typing import Dict, List, Optional, Tuple, Union, Any, Callable
from dataclasses import dataclass, field
from enum import Enum
import asyncio
import time
import math
import statistics
import json
import numpy as np
from datetime import datetime, timedelta
import random
import hashlib
import os
from abc import ABC, abstractmethod

# ================ Enums ================

class OutputFormat(Enum):
    """ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ Ø®Ø±ÙˆØ¬ÛŒ"""
    TEXT = "text"
    HTML = "html"
    MARKDOWN = "markdown"
    JSON = "json"
    PROMETHEUS = "prometheus"

class TransferStatus(Enum):
    """ÙˆØ¶Ø¹ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø§Ù†ØªÙ‚Ø§Ù„"""
    PENDING = "pending"
    TRANSFERRING = "transferring"
    COMPLETED = "completed"
    FAILED = "failed"
    PAUSED = "paused"
    CANCELLED = "cancelled"

class NetworkQuality(Enum):
    """Ú©ÛŒÙÛŒØª Ø´Ø¨Ú©Ù‡"""
    EXCELLENT = "excellent"
    GOOD = "good"
    FAIR = "fair"
    POOR = "poor"
    UNSTABLE = "unstable"

# ================ Core Classes ================

@dataclass
class TransferMetrics:
    """Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø§Ù†ØªÙ‚Ø§Ù„"""
    transferred: int = 0
    total: int = 0
    speed: float = 0.0
    elapsed: float = 0.0
    remaining: float = 0.0
    start_time: float = field(default_factory=time.time)
    end_time: Optional[float] = None
    speed_history: List[float] = field(default_factory=list)
    latency_history: List[float] = field(default_factory=list)
    error_count: int = 0
    
    @property
    def percent(self) -> float:
        return (self.transferred / self.total * 100) if self.total > 0 else 0.0
    
    @property
    def avg_speed(self) -> float:
        return statistics.mean(self.speed_history) if self.speed_history else 0.0
    
    @property
    def max_speed(self) -> float:
        return max(self.speed_history) if self.speed_history else 0.0
    
    @property
    def min_speed(self) -> float:
        return min(self.speed_history) if self.speed_history else 0.0

@dataclass
class ProgressConfig:
    """ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ´Ø±ÙØª"""
    show_percentage: bool = True
    show_speed: bool = True
    show_time: bool = True
    show_graph: bool = False
    graph_width: int = 30
    graph_height: int = 5
    refresh_rate: float = 0.1  # seconds
    use_colors: bool = True
    show_eta: bool = True
    show_size: bool = True
    compact_mode: bool = False
    language: str = "fa"  # fa, en

# ================ Main Progress UI ================

class ProgressUI:
    """UI Ø§ØµÙ„ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ´Ø±ÙØª"""
    
    # Ø±Ù†Ú¯â€ŒÙ‡Ø§ÛŒ ØªØ±Ù…ÛŒÙ†Ø§Ù„
    COLORS = {
        'red': '\033[91m',
        'green': '\033[92m',
        'yellow': '\033[93m',
        'blue': '\033[94m',
        'magenta': '\033[95m',
        'cyan': '\033[96m',
        'white': '\033[97m',
        'reset': '\033[0m',
        'bold': '\033[1m',
        'dim': '\033[2m'
    }
    
    # Ù†Ù…Ø§Ø¯Ù‡Ø§
    SYMBOLS = {
        'bar_filled': 'â–ˆ',
        'bar_empty': 'â–‘',
        'arrow_right': 'â†’',
        'arrow_up': 'â†‘',
        'arrow_down': 'â†“',
        'check': 'âœ“',
        'cross': 'âœ—',
        'warning': 'âš ',
        'info': 'â„¹',
        'spinner': ['â ‹', 'â ™', 'â ¹', 'â ¸', 'â ¼', 'â ´', 'â ¦', 'â §', 'â ‡', 'â ']
    }
    
    def __init__(self, config: Optional[ProgressConfig] = None):
        self.config = config or ProgressConfig()
        self._spinner_index = 0
        self._last_update_time = time.time()
        self._frame_count = 0
    
    # ================ ÙØ±Ù…Øªâ€ŒØ¨Ù†Ø¯ÛŒ ================
    
    @staticmethod
    def format_size(bytes_count: int, precision: int = 2) -> str:
        """Ù‚Ø§Ù„Ø¨â€ŒØ¨Ù†Ø¯ÛŒ Ø§Ù†Ø¯Ø§Ø²Ù‡ ÙØ§ÛŒÙ„"""
        for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
            if bytes_count < 1024.0 or unit == 'TB':
                break
            bytes_count /= 1024.0
        return f"{bytes_count:.{precision}f} {unit}"
    
    @staticmethod
    def format_speed(bytes_per_second: float, precision: int = 2) -> str:
        """Ù‚Ø§Ù„Ø¨â€ŒØ¨Ù†Ø¯ÛŒ Ø³Ø±Ø¹Øª"""
        for unit in ['B/s', 'KB/s', 'MB/s', 'GB/s']:
            if bytes_per_second < 1024.0 or unit == 'GB/s':
                break
            bytes_per_second /= 1024.0
        return f"{bytes_per_second:.{precision}f} {unit}"
    
    @staticmethod
    def format_time(seconds: float, detailed: bool = False) -> str:
        """Ù‚Ø§Ù„Ø¨â€ŒØ¨Ù†Ø¯ÛŒ Ø²Ù…Ø§Ù†"""
        if seconds < 60:
            return f"{seconds:.0f} Ø«Ø§Ù†ÛŒÙ‡" if not detailed else f"{seconds:.1f} Ø«Ø§Ù†ÛŒÙ‡"
        
        minutes, seconds = divmod(seconds, 60)
        if minutes < 60:
            return f"{minutes:.0f}:{seconds:02.0f}"
        
        hours, minutes = divmod(minutes, 60)
        if hours < 24:
            return f"{hours:.0f}:{minutes:02.0f}:{seconds:02.0f}"
        
        days, hours = divmod(hours, 24)
        return f"{days} Ø±ÙˆØ² {hours:.0f}:{minutes:02.0f}"
    
    @staticmethod
    def format_timestamp(timestamp: float) -> str:
        """Ù‚Ø§Ù„Ø¨â€ŒØ¨Ù†Ø¯ÛŒ timestamp"""
        dt = datetime.fromtimestamp(timestamp)
        return dt.strftime("%Y-%m-%d %H:%M:%S")
    
    # ================ Progress Bars ================
    
    def create_progress_bar(self, percent: float, width: int = 20, 
                          color_gradient: bool = True) -> str:
        """Ø§ÛŒØ¬Ø§Ø¯ progress bar Ú¯Ø±Ø§ÙÛŒÚ©ÛŒ"""
        if percent < 0:
            percent = 0
        elif percent > 100:
            percent = 100
        
        filled = int(width * percent / 100)
        empty = width - filled
        
        if color_gradient and self.config.use_colors:
            if percent < 30:
                color = self.COLORS['red']
            elif percent < 70:
                color = self.COLORS['yellow']
            else:
                color = self.COLORS['green']
        else:
            color = ''
        
        bar = color + self.SYMBOLS['bar_filled'] * filled + \
              self.COLORS['dim'] + self.SYMBOLS['bar_empty'] * empty + \
              self.COLORS['reset']
        
        return f"[{bar}]"
    
    def create_multi_segment_bar(self, segments: List[Tuple[float, str]], 
                                width: int = 30) -> str:
        """Ø§ÛŒØ¬Ø§Ø¯ progress bar Ø¨Ø§ Ú†Ù†Ø¯ÛŒÙ† Ø¨Ø®Ø´ Ø±Ù†Ú¯ÛŒ"""
        total = sum(s[0] for s in segments)
        if total == 0:
            return "[" + " " * width + "]"
        
        result = []
        for value, color_code in segments:
            segment_width = int(width * value / total)
            if color_code in self.COLORS:
                result.append(self.COLORS[color_code] + 
                            self.SYMBOLS['bar_filled'] * segment_width)
            else:
                result.append(self.SYMBOLS['bar_filled'] * segment_width)
        
        # Ù¾Ø± Ú©Ø±Ø¯Ù† ÙØ¶Ø§ÛŒ Ø®Ø§Ù„ÛŒ
        total_width = sum(len(r) for r in result if r.startswith('\033'))
        empty_width = width - total_width
        if empty_width > 0:
            result.append(self.COLORS['dim'] + 
                         self.SYMBOLS['bar_empty'] * empty_width)
        
        return "[" + "".join(result) + self.COLORS['reset'] + "]"
    
    # ================ Ù†Ù…Ø§ÛŒØ´â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØª ================
    
    def create_detailed_progress(self, metrics: TransferMetrics, 
                                show_graph: bool = True) -> str:
        """Ø§ÛŒØ¬Ø§Ø¯ Ù…ØªÙ† Ù¾ÛŒØ´Ø±ÙØª Ø¨Ø§ Ø¬Ø²Ø¦ÛŒØ§Øª Ú©Ø§Ù…Ù„"""
        lines = []
        
        # Ù‡Ø¯Ø±
        lines.append(f"{self.COLORS['bold']}ğŸ“Š Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ´Ø±ÙØª Ø§Ù†ØªÙ‚Ø§Ù„{self.COLORS['reset']}")
        lines.append("â”€" * 40)
        
        # Progress bar
        bar = self.create_progress_bar(metrics.percent, 40)
        lines.append(f"{bar} {metrics.percent:.1f}%")
        
        # Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§ØµÙ„ÛŒ
        if self.config.show_size:
            transferred_fmt = self.format_size(metrics.transferred)
            total_fmt = self.format_size(metrics.total)
            lines.append(f"ğŸ“¦ Ø­Ø¬Ù…: {transferred_fmt} / {total_fmt}")
        
        if self.config.show_speed:
            speed_fmt = self.format_speed(metrics.speed)
            avg_speed_fmt = self.format_speed(metrics.avg_speed)
            lines.append(f"âš¡ Ø³Ø±Ø¹Øª: {speed_fmt} (Ù…ØªÙˆØ³Ø·: {avg_speed_fmt})")
        
        if self.config.show_time:
            elapsed_fmt = self.format_time(metrics.elapsed)
            remaining_fmt = self.format_time(metrics.remaining)
            lines.append(f"â±ï¸ Ø³Ù¾Ø±ÛŒ Ø´Ø¯Ù‡: {elapsed_fmt}")
            
            if self.config.show_eta and metrics.remaining > 0:
                eta_time = time.time() + metrics.remaining
                eta_str = datetime.fromtimestamp(eta_time).strftime("%H:%M:%S")
                lines.append(f"â³ Ø¨Ø§Ù‚ÛŒÙ…Ø§Ù†Ø¯Ù‡: {remaining_fmt} (ØªØ§ {eta_str})")
        
        # Ù†Ù…ÙˆØ¯Ø§Ø± Ø³Ø±Ø¹Øª
        if show_graph and metrics.speed_history and len(metrics.speed_history) > 5:
            lines.append("")
            lines.append("ğŸ“ˆ Ù†Ù…ÙˆØ¯Ø§Ø± Ø³Ø±Ø¹Øª:")
            lines.append(self.create_speed_graph(metrics.speed_history, 
                                                self.config.graph_width, 
                                                self.config.graph_height))
        
        # Ø¢Ù…Ø§Ø± Ø§Ø¶Ø§ÙÛŒ
        if metrics.error_count > 0:
            lines.append(f"{self.COLORS['yellow']}âš  Ø®Ø·Ø§Ù‡Ø§: {metrics.error_count}{self.COLORS['reset']}")
        
        return "\n".join(lines)
    
    def create_mini_progress(self, metrics: TransferMetrics) -> str:
        """Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…Ø§ÛŒØ´ Ù…ÛŒÙ†ÛŒØ§ØªÙˆØ±ÛŒ"""
        bar = self.create_progress_bar(metrics.percent, 10, False)
        speed_fmt = self.format_speed(metrics.speed)
        return f"{bar} {metrics.percent:.1f}% âš¡{speed_fmt}"
    
    # ================ Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ Ùˆ Ú¯Ø±Ø§Ùâ€ŒÙ‡Ø§ ================
    
    def create_speed_graph(self, speed_history: List[float], 
                          width: int = 30, height: int = 5) -> str:
        """Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆØ¯Ø§Ø± Ø³Ø±Ø¹Øª ASCII"""
        if not speed_history or len(speed_history) < 2:
            return "ğŸ“ˆ (Ø¯Ø§Ø¯Ù‡ Ú©Ø§ÙÛŒ Ù†ÛŒØ³Øª)"
        
        # Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† ØªØ§Ø±ÛŒØ®Ú†Ù‡
        data = speed_history[-width:] if len(speed_history) > width else speed_history
        
        # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù…Ø­Ø¯ÙˆØ¯Ù‡
        min_val = min(data)
        max_val = max(data)
        
        if max_val - min_val < 0.0001:
            return "ğŸ“ˆ (Ø¯Ø§Ø¯Ù‡ Ø«Ø§Ø¨Øª)"
        
        # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ
        normalized = [(val - min_val) / (max_val - min_val) for val in data]
        
        # Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆØ¯Ø§Ø±
        chart_rows = []
        for y in range(height - 1, -1, -1):
            threshold = y / height
            row_chars = []
            
            for value in normalized:
                if value >= threshold:
                    if value >= 0.8:
                        row_chars.append(self.SYMBOLS['bar_filled'])
                    elif value >= 0.5:
                        row_chars.append('â–“')
                    elif value >= 0.3:
                        row_chars.append('â–’')
                    else:
                        row_chars.append('â–‘')
                else:
                    row_chars.append(' ')
            
            chart_rows.append(''.join(row_chars))
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù…Ø­ÙˆØ±
        chart_rows.append('â”€' * len(data))
        
        # Ù…Ù‚Ø§Ø¯ÛŒØ± min/max
        min_fmt = self.format_speed(min_val)
        max_fmt = self.format_speed(max_val)
        chart_rows.append(f"â†•ï¸ {min_fmt} â€“ {max_fmt}")
        
        return '\n'.join(chart_rows)
    
    def create_comparison_chart(self, datasets: Dict[str, List[float]], 
                               width: int = 40, height: int = 8) -> str:
        """Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆØ¯Ø§Ø± Ù…Ù‚Ø§ÛŒØ³Ù‡â€ŒØ§ÛŒ"""
        if not datasets:
            return "ğŸ“Š (Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª)"
        
        # Ø±Ù†Ú¯â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø¨Ø±Ø§ÛŒ Ø¯ÛŒØªØ§Ø³Øªâ€ŒÙ‡Ø§
        colors = [self.COLORS['green'], self.COLORS['blue'], 
                 self.COLORS['yellow'], self.COLORS['magenta']]
        
        # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù‡Ù…Ù‡ Ø¯ÛŒØªØ§Ø³Øªâ€ŒÙ‡Ø§
        all_data = []
        for data in datasets.values():
            all_data.extend(data[-width:])
        
        max_val = max(all_data) if all_data else 1
        
        # Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆØ¯Ø§Ø±
        chart = []
        for y in range(height - 1, -1, -1):
            threshold = y / height
            row = [' '] * width
            
            for i, (name, data) in enumerate(datasets.items()):
                color = colors[i % len(colors)]
                for x in range(min(width, len(data))):
                    value = data[x] / max_val if max_val > 0 else 0
                    if value >= threshold:
                        row[x] = color + 'â–ˆ' + self.COLORS['reset']
            
            chart.append(''.join(row))
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† legend
        chart.append('â”€' * width)
        legend = []
        for i, name in enumerate(datasets.keys()):
            color = colors[i % len(colors)]
            legend.append(f"{color}â–ˆ{self.COLORS['reset']} {name}")
        
        chart.append(' | '.join(legend))
        
        return '\n'.join(chart)
    
    # ================ Ø§Ù†ÛŒÙ…ÛŒØ´Ù†â€ŒÙ‡Ø§ ================
    
    def get_spinner(self, text: str = "") -> str:
        """Ø¯Ø±ÛŒØ§ÙØª Ø§Ø³Ù¾ÛŒÙ†Ø± Ø§Ù†ÛŒÙ…ÛŒØ´Ù†"""
        frame = self.SYMBOLS['spinner'][self._spinner_index]
        self._spinner_index = (self._spinner_index + 1) % len(self.SYMBOLS['spinner'])
        
        if text:
            return f"{frame} {text}"
        return frame
    
    def create_loading_animation(self, stage: str = "", 
                                details: str = "") -> str:
        """Ø§ÛŒØ¬Ø§Ø¯ Ø§Ù†ÛŒÙ…ÛŒØ´Ù† Ù„ÙˆØ¯ÛŒÙ†Ú¯"""
        spinner = self.get_spinner()
        
        stages = {
            'connecting': "Ø¯Ø± Ø­Ø§Ù„ Ø§ØªØµØ§Ù„",
            'downloading': "Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯",
            'uploading': "Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù¾Ù„ÙˆØ¯",
            'processing': "Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´",
            'encrypting': "Ø¯Ø± Ø­Ø§Ù„ Ø±Ù…Ø²Ù†Ú¯Ø§Ø±ÛŒ",
            'decrypting': "Ø¯Ø± Ø­Ø§Ù„ Ø±Ù…Ø²Ú¯Ø´Ø§ÛŒÛŒ",
            'compressing': "Ø¯Ø± Ø­Ø§Ù„ ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ",
            'extracting': "Ø¯Ø± Ø­Ø§Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬",
            'verifying': "Ø¯Ø± Ø­Ø§Ù„ ØªØ£ÛŒÛŒØ¯",
            'cleaning': "Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ"
        }
        
        stage_text = stages.get(stage, "Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´")
        
        if details:
            return f"{spinner} {stage_text}: {details}"
        return f"{spinner} {stage_text}..."
    
    # ================ Ø®Ù„Ø§ØµÙ‡â€ŒÚ¯ÛŒØ±ÛŒ ================
    
    def create_transfer_summary(self, metrics: TransferMetrics, 
                              transfer_type: str = "download",
                              filename: str = "") -> str:
        """Ø§ÛŒØ¬Ø§Ø¯ Ø®Ù„Ø§ØµÙ‡ Ø§Ù†ØªÙ‚Ø§Ù„"""
        lines = []
        
        emoji = "ğŸ“¥" if transfer_type == "download" else "ğŸ“¤"
        action = "Ø¯Ø§Ù†Ù„ÙˆØ¯" if transfer_type == "download" else "Ø¢Ù¾Ù„ÙˆØ¯"
        
        lines.append(f"{emoji} {self.COLORS['bold']}{action} ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯{self.COLORS['reset']}")
        lines.append("=" * 40)
        
        if filename:
            lines.append(f"ğŸ“ ÙØ§ÛŒÙ„: {filename}")
        
        lines.append(f"ğŸ“Š Ù¾ÛŒØ´Ø±ÙØª: {metrics.percent:.1f}%")
        lines.append(f"ğŸ’¾ Ø­Ø¬Ù… Ú©Ù„: {self.format_size(metrics.total)}")
        lines.append(f"â±ï¸ Ø²Ù…Ø§Ù† Ú©Ù„: {self.format_time(metrics.elapsed, True)}")
        lines.append(f"âš¡ Ø³Ø±Ø¹Øª Ù…ØªÙˆØ³Ø·: {self.format_speed(metrics.avg_speed)}")
        lines.append(f"ğŸš€ Ø­Ø¯Ø§Ú©Ø«Ø± Ø³Ø±Ø¹Øª: {self.format_speed(metrics.max_speed)}")
        
        # Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯
        efficiency = self._calculate_efficiency(metrics)
        lines.append(f"â­ Ú©Ø§Ø±Ø§ÛŒÛŒ: {efficiency['rating']} {efficiency['emoji']}")
        
        # Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§
        if metrics.speed_history:
            lines.append(f"ğŸ“ˆ Ù†Ù‚Ø§Ø· Ø¯Ø§Ø¯Ù‡: {len(metrics.speed_history)}")
        
        if metrics.error_count > 0:
            lines.append(f"{self.COLORS['yellow']}âš  Ø®Ø·Ø§Ù‡Ø§ÛŒ Ø±Ø® Ø¯Ø§Ø¯Ù‡: {metrics.error_count}{self.COLORS['reset']}")
        
        return "\n".join(lines)
    
    def _calculate_efficiency(self, metrics: TransferMetrics) -> Dict:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ú©Ø§Ø±Ø§ÛŒÛŒ Ø§Ù†ØªÙ‚Ø§Ù„"""
        if metrics.total == 0 or metrics.elapsed == 0:
            return {"rating": "Ù†Ø§Ù…Ø´Ø®Øµ", "emoji": "â“", "score": 0}
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ù…Ø±Ù‡ Ú©Ø§Ø±Ø§ÛŒÛŒ (0-100)
        speed_score = min(100, metrics.avg_speed / (1024 * 1024) * 10)  # 10MB/s = 100
        
        stability_score = 0
        if len(metrics.speed_history) > 10:
            std_dev = statistics.stdev(metrics.speed_history[-10:])
            mean_speed = statistics.mean(metrics.speed_history[-10:])
            if mean_speed > 0:
                cv = std_dev / mean_speed
                stability_score = max(0, 100 - cv * 1000)
        
        error_penalty = metrics.error_count * 5
        total_score = max(0, (speed_score * 0.7 + stability_score * 0.3) - error_penalty)
        
        # ØªØ¹ÛŒÛŒÙ† Ø±ØªØ¨Ù‡
        if total_score >= 90:
            return {"rating": "Ø¹Ø§Ù„ÛŒ", "emoji": "ğŸš€", "score": total_score}
        elif total_score >= 70:
            return {"rating": "Ø®ÙˆØ¨", "emoji": "ğŸ‘", "score": total_score}
        elif total_score >= 50:
            return {"rating": "Ù…ØªÙˆØ³Ø·", "emoji": "ğŸ“¶", "score": total_score}
        else:
            return {"rating": "Ø¶Ø¹ÛŒÙ", "emoji": "ğŸŒ", "score": total_score}

# ================ AIPredictionProgress ================

class AIPredictionProgress:
    """Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø§ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ ML"""
    
    def __init__(self, ui: ProgressUI):
        self.ui = ui
        self.patterns = []
        self.history_buffer = []
        self.max_history = 100
        
    def predict_completion(self, metrics: TransferMetrics) -> Dict:
        """Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø²Ù…Ø§Ù† ØªÚ©Ù…ÛŒÙ„ Ø¨Ø§ ØªØ­Ù„ÛŒÙ„ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø³Ø±Ø¹Øª"""
        if len(metrics.speed_history) < 5:
            return self._simple_prediction(metrics)
        
        # Ø°Ø®ÛŒØ±Ù‡ ØªØ§Ø±ÛŒØ®Ú†Ù‡
        self.history_buffer.append({
            'timestamp': time.time(),
            'speed': metrics.speed,
            'transferred': metrics.transferred,
            'remaining': metrics.total - metrics.transferred
        })
        
        if len(self.history_buffer) > self.max_history:
            self.history_buffer.pop(0)
        
        # ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
        predictions = {
            'linear': self._linear_regression_prediction(metrics),
            'exponential': self._exponential_smoothing_prediction(metrics),
            'pattern': self._pattern_matching_prediction(metrics),
            'neural': self._neural_network_prediction(metrics) if len(self.history_buffer) > 20 else None
        }
        
        # ØªØ±Ú©ÛŒØ¨ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ‡Ø§
        valid_preds = [p for p in predictions.values() if p is not None]
        if not valid_preds:
            return self._simple_prediction(metrics)
        
        # Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† ÙˆØ²Ù†ÛŒ
        weights = {'linear': 0.3, 'exponential': 0.3, 'pattern': 0.2, 'neural': 0.2}
        weighted_remaining = 0
        total_weight = 0
        
        for method, pred in predictions.items():
            if pred is not None:
                weight = weights.get(method, 0.1)
                weighted_remaining += pred['remaining_time'] * weight
                total_weight += weight
        
        avg_remaining = weighted_remaining / total_weight if total_weight > 0 else metrics.remaining
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ø¹ØªÙ…Ø§Ø¯
        confidence = self._calculate_confidence(predictions, metrics)
        
        # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø³Ø±Ø¹Øª Ø¢ÛŒÙ†Ø¯Ù‡
        future_speeds = self._predict_future_speeds(metrics)
        
        return {
            'remaining_time': avg_remaining,
            'confidence': confidence,
            'completion_time': time.time() + avg_remaining,
            'future_speeds': future_speeds,
            'method': 'ai_ensemble',
            'predictions': {k: v for k, v in predictions.items() if v is not None},
            'scenarios': self._generate_scenarios(metrics, avg_remaining)
        }
    
    def _simple_prediction(self, metrics: TransferMetrics) -> Dict:
        """Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø³Ø§Ø¯Ù‡"""
        if metrics.speed > 0:
            remaining_time = (metrics.total - metrics.transferred) / metrics.speed
        else:
            remaining_time = float('inf')
        
        return {
            'remaining_time': remaining_time,
            'confidence': 0.3,
            'completion_time': time.time() + remaining_time,
            'method': 'simple',
            'scenarios': {
                'optimistic': remaining_time * 0.8,
                'realistic': remaining_time,
                'pessimistic': remaining_time * 1.5
            }
        }
    
    def _linear_regression_prediction(self, metrics: TransferMetrics) -> Optional[Dict]:
        """Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¨Ø§ Ø±Ú¯Ø±Ø³ÛŒÙˆÙ† Ø®Ø·ÛŒ"""
        if len(metrics.speed_history) < 10:
            return None
        
        try:
            x = np.arange(len(metrics.speed_history))
            y = np.array(metrics.speed_history)
            
            # Ø±Ú¯Ø±Ø³ÛŒÙˆÙ† Ø®Ø·ÛŒ
            z = np.polyfit(x, y, 1)
            slope = z[0]
            intercept = z[1]
            
            # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø³Ø±Ø¹Øª Ø¢ÛŒÙ†Ø¯Ù‡
            future_speed = slope * len(metrics.speed_history) + intercept
            
            # Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø³Ø±Ø¹Øª Ù…Ù†ÙÛŒ
            future_speed = max(future_speed, 1000)  # Ø­Ø¯Ø§Ù‚Ù„ 1KB/s
            
            remaining = metrics.total - metrics.transferred
            remaining_time = remaining / future_speed if future_speed > 0 else float('inf')
            
            return {
                'remaining_time': remaining_time,
                'predicted_speed': future_speed,
                'trend': 'increasing' if slope > 0.01 else 'decreasing' if slope < -0.01 else 'stable',
                'trend_strength': abs(slope),
                'method': 'linear_regression'
            }
        except:
            return None
    
    def _calculate_confidence(self, predictions: Dict, metrics: TransferMetrics) -> float:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø³Ø·Ø­ Ø§Ø¹ØªÙ…Ø§Ø¯ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ"""
        if not predictions:
            return 0.0
        
        # Ø¹ÙˆØ§Ù…Ù„ Ù…Ø¤Ø«Ø± Ø¯Ø± Ø§Ø¹ØªÙ…Ø§Ø¯
        factors = []
        
        # 1. ØªØ¹Ø¯Ø§Ø¯ Ù†Ù‚Ø§Ø· Ø¯Ø§Ø¯Ù‡
        data_points_factor = min(1.0, len(metrics.speed_history) / 50)
        factors.append(data_points_factor * 0.3)
        
        # 2. Ù‡Ù…Ø®ÙˆØ§Ù†ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ‡Ø§
        if len(predictions) > 1:
            times = [p['remaining_time'] for p in predictions.values() if p is not None]
            std_dev = statistics.stdev(times) if len(times) > 1 else 0
            mean_time = statistics.mean(times)
            
            if mean_time > 0:
                consistency = max(0, 1 - (std_dev / mean_time))
                factors.append(consistency * 0.4)
        
        # 3. Ø«Ø¨Ø§Øª Ø³Ø±Ø¹Øª
        if len(metrics.speed_history) > 5:
            recent_speeds = metrics.speed_history[-5:]
            cv = statistics.stdev(recent_speeds) / statistics.mean(recent_speeds) \
                 if statistics.mean(recent_speeds) > 0 else 1
            stability = max(0, 1 - cv)
            factors.append(stability * 0.3)
        
        return min(1.0, max(0.0, sum(factors)))
    
    def _generate_scenarios(self, metrics: TransferMetrics, base_remaining: float) -> Dict:
        """ØªÙˆÙ„ÛŒØ¯ Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù"""
        if not metrics.speed_history:
            return {}
        
        recent_speeds = metrics.speed_history[-10:] if len(metrics.speed_history) >= 10 else metrics.speed_history
        avg_speed = statistics.mean(recent_speeds)
        min_speed = min(recent_speeds)
        max_speed = max(recent_speeds)
        
        remaining = metrics.total - metrics.transferred
        
        return {
            'worst_case': remaining / min_speed if min_speed > 0 else float('inf'),
            'likely_case': base_remaining,
            'best_case': remaining / max_speed if max_speed > 0 else float('inf'),
            'average_case': remaining / avg_speed if avg_speed > 0 else float('inf')
        }
    
    def _predict_future_speeds(self, metrics: TransferMetrics, steps: int = 10) -> List[float]:
        """Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø³Ø±Ø¹Øªâ€ŒÙ‡Ø§ÛŒ Ø¢ÛŒÙ†Ø¯Ù‡"""
        if len(metrics.speed_history) < 5:
            return [metrics.speed] * steps
        
        # Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØªØ­Ø±Ú©
        window_size = min(5, len(metrics.speed_history))
        last_speeds = metrics.speed_history[-window_size:]
        
        # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø³Ø§Ø¯Ù‡: Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø§Ø®ÛŒØ±
        avg_speed = statistics.mean(last_speeds)
        
        # Ú©Ù…ÛŒ ØªØºÛŒÛŒØ± Ø¨Ø±Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒâ€ŒØªØ± Ø´Ø¯Ù†
        return [avg_speed * (0.9 + 0.2 * random.random()) for _ in range(steps)]

# ================ MultiFileProgress ================

class MultiFileProgress:
    """Ù…Ø¯ÛŒØ±ÛŒØª Ù¾ÛŒØ´Ø±ÙØª Ú†Ù†Ø¯ÛŒÙ† ÙØ§ÛŒÙ„ Ù‡Ù…Ø²Ù…Ø§Ù†"""
    
    def __init__(self, ui: ProgressUI):
        self.ui = ui
        self.files: Dict[str, Dict] = {}
        self.overall_metrics = TransferMetrics()
        self.current_file_id: Optional[str] = None
        self.start_time = time.time()
        self.completion_order = []
    
    def add_file(self, file_id: str, filename: str, size: int, 
                priority: int = 1, metadata: Optional[Dict] = None):
        """Ø§ÙØ²ÙˆØ¯Ù† ÙØ§ÛŒÙ„ Ø¬Ø¯ÛŒØ¯"""
        self.files[file_id] = {
            'id': file_id,
            'name': filename,
            'size': size,
            'transferred': 0,
            'priority': priority,
            'status': TransferStatus.PENDING,
            'metrics': TransferMetrics(total=size),
            'metadata': metadata or {},
            'added_time': time.time(),
            'start_time': None,
            'end_time': None,
            'error': None
        }
        
        self.overall_metrics.total += size
    
    def update_file_progress(self, file_id: str, transferred: int, 
                           speed: Optional[float] = None):
        """Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù¾ÛŒØ´Ø±ÙØª ÙØ§ÛŒÙ„"""
        if file_id not in self.files:
            return
        
        file = self.files[file_id]
        old_transferred = file['transferred']
        
        # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ÙØ§ÛŒÙ„
        file['transferred'] = transferred
        file['metrics'].transferred = transferred
        
        if speed is not None:
            file['metrics'].speed = speed
            file['metrics'].speed_history.append(speed)
        
        # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ú©Ù„ÛŒ
        delta = transferred - old_transferred
        self.overall_metrics.transferred += delta
        
        # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø²Ù…Ø§Ù†
        if file['status'] == TransferStatus.PENDING:
            file['status'] = TransferStatus.TRANSFERRING
            file['start_time'] = time.time()
        
        file['metrics'].elapsed = time.time() - (file['start_time'] or time.time())
        
        # Ø¨Ø±Ø±Ø³ÛŒ ØªÚ©Ù…ÛŒÙ„
        if transferred >= file['size']:
            self._complete_file(file_id)
    
    def _complete_file(self, file_id: str):
        """Ø¹Ù„Ø§Ù…Øªâ€ŒÚ¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯Ù‡"""
        file = self.files[file_id]
        file['status'] = TransferStatus.COMPLETED
        file['end_time'] = time.time()
        file['metrics'].end_time = file['end_time']
        
        self.completion_order.append(file_id)
        
        # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ
        self.overall_metrics.completed_files = len([f for f in self.files.values() 
                                                  if f['status'] == TransferStatus.COMPLETED])
    
    def create_dashboard(self, show_details: bool = True) -> str:
        """Ø§ÛŒØ¬Ø§Ø¯ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ù…Ø¯ÛŒØ±ÛŒØª Ú†Ù†Ø¯ ÙØ§ÛŒÙ„"""
        lines = []
        
        # Ù‡Ø¯Ø±
        lines.append(f"{self.ui.COLORS['bold']}ğŸ“ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ø§Ù†ØªÙ‚Ø§Ù„ Ú†Ù†Ø¯ ÙØ§ÛŒÙ„ÛŒ{self.ui.COLORS['reset']}")
        lines.append("â•" * 50)
        
        # Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ
        total_files = len(self.files)
        completed = len([f for f in self.files.values() 
                        if f['status'] == TransferStatus.COMPLETED])
        transferring = len([f for f in self.files.values() 
                           if f['status'] == TransferStatus.TRANSFERRING])
        failed = len([f for f in self.files.values() 
                     if f['status'] == TransferStatus.FAILED])
        
        overall_percent = (self.overall_metrics.transferred / 
                          self.overall_metrics.total * 100) if self.overall_metrics.total > 0 else 0
        
        lines.append(f"ğŸ“Š ÙˆØ¶Ø¹ÛŒØª Ú©Ù„ÛŒ: {completed}/{total_files} ÙØ§ÛŒÙ„ ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯Ù‡")
        lines.append(f"   â”œâ”€ ğŸ”„ Ø¯Ø± Ø­Ø§Ù„ Ø§Ù†ØªÙ‚Ø§Ù„: {transferring}")
        lines.append(f"   â”œâ”€ âŒ Ù†Ø§Ù…ÙˆÙÙ‚: {failed}")
        lines.append(f"   â””â”€ â³ Ù…Ù†ØªØ¸Ø±: {total_files - completed - transferring - failed}")
        lines.append("")
        
        # Progress bar Ú©Ù„ÛŒ
        overall_bar = self.ui.create_progress_bar(overall_percent, 40)
        lines.append(f"ğŸ“ˆ Ù¾ÛŒØ´Ø±ÙØª Ú©Ù„ÛŒ: {overall_bar} {overall_percent:.1f}%")
        lines.append(f"   ğŸ“¦ Ø­Ø¬Ù…: {self.ui.format_size(self.overall_metrics.transferred)} / "
                    f"{self.ui.format_size(self.overall_metrics.total)}")
        lines.append("")
        
        if show_details:
            # Ù„ÛŒØ³Øª ÙØ§ÛŒÙ„â€ŒÙ‡Ø§
            lines.append(f"{self.ui.COLORS['dim']}ÙØ§ÛŒÙ„â€ŒÙ‡Ø§:{self.ui.COLORS['reset']}")
            
            for file_id, file in sorted(self.files.items(), 
                                       key=lambda x: x[1]['priority'], 
                                       reverse=True):
                status_icons = {
                    TransferStatus.PENDING: "â³",
                    TransferStatus.TRANSFERRING: "ğŸ”„",
                    TransferStatus.COMPLETED: "âœ…",
                    TransferStatus.FAILED: "âŒ",
                    TransferStatus.PAUSED: "â¸ï¸",
                    TransferStatus.CANCELLED: "ğŸš«"
                }
                
                icon = status_icons.get(file['status'], "â“")
                percent = (file['transferred'] / file['size'] * 100) if file['size'] > 0 else 0
                
                # Ù†Ù…Ø§ÛŒØ´ Ú©ÙˆØªØ§Ù‡
                name_display = file['name']
                if len(name_display) > 30:
                    name_display = name_display[:27] + "..."
                
                if file['status'] == TransferStatus.TRANSFERRING:
                    speed_fmt = self.ui.format_speed(file['metrics'].speed)
                    file_line = f"  {icon} {name_display:<30} {percent:5.1f}% âš¡{speed_fmt}"
                else:
                    file_line = f"  {icon} {name_display:<30} {percent:5.1f}%"
                
                lines.append(file_line)
        
        # Ø²Ù…Ø§Ù† ØªØ®Ù…ÛŒÙ†ÛŒ Ø¨Ø§Ù‚ÛŒÙ…Ø§Ù†Ø¯Ù‡
        if transferring > 0 and self.overall_metrics.speed > 0:
            remaining = self.overall_metrics.total - self.overall_metrics.transferred
            eta_seconds = remaining / self.overall_metrics.speed
            eta_time = datetime.now() + timedelta(seconds=eta_seconds)
            eta_str = eta_time.strftime("%H:%M:%S")
            
            lines.append("")
            lines.append(f"â³ ØªØ®Ù…ÛŒÙ† Ø²Ù…Ø§Ù† ØªÚ©Ù…ÛŒÙ„: Ø­Ø¯ÙˆØ¯ {self.ui.format_time(eta_seconds)} "
                        f"(Ø³Ø§Ø¹Øª {eta_str})")
        
        return "\n".join(lines)
    
    def get_file_stats(self) -> Dict:
        """Ø¯Ø±ÛŒØ§ÙØª Ø¢Ù…Ø§Ø± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§"""
        stats = {
            'total_files': len(self.files),
            'completed': 0,
            'transferring': 0,
            'failed': 0,
            'pending': 0,
            'total_size': self.overall_metrics.total,
            'transferred_size': self.overall_metrics.transferred,
            'average_speed': 0,
            'start_time': self.start_time,
            'current_time': time.time()
        }
        
        speeds = []
        for file in self.files.values():
            if file['status'] == TransferStatus.COMPLETED:
                stats['completed'] += 1
            elif file['status'] == TransferStatus.TRANSFERRING:
                stats['transferring'] += 1
                speeds.append(file['metrics'].speed)
            elif file['status'] == TransferStatus.FAILED:
                stats['failed'] += 1
            elif file['status'] == TransferStatus.PENDING:
                stats['pending'] += 1
        
        if speeds:
            stats['average_speed'] = statistics.mean(speeds)
        
        return stats

# ================ AdaptiveTransferOptimizer ================

class AdaptiveTransferOptimizer:
    """Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø§Ù†ØªÙ‚Ø§Ù„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø´Ø±Ø§ÛŒØ· Ø´Ø¨Ú©Ù‡"""
    
    def __init__(self):
        self.chunk_sizes = {
            'poor': 4 * 1024,           # 4KB
            'fair': 16 * 1024,          # 16KB
            'good': 64 * 1024,          # 64KB
            'excellent': 256 * 1024,    # 256KB
            'perfect': 1024 * 1024      # 1MB
        }
        
        self.current_chunk_size = self.chunk_sizes['good']
        self.network_quality_history: List[NetworkQuality] = []
        self.optimization_history = []
        self.last_optimization_time = time.time()
        self.optimization_interval = 5  # Ø«Ø§Ù†ÛŒÙ‡
        
    def analyze_network(self, speed_history: List[float], 
                       latency_samples: List[float],
                       error_rate: float = 0.0) -> Dict:
        """Ø¢Ù†Ø§Ù„ÛŒØ² Ú©ÛŒÙÛŒØª Ø´Ø¨Ú©Ù‡"""
        
        if not speed_history:
            return self._get_default_optimization()
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø´Ø¨Ú©Ù‡
        recent_speeds = speed_history[-10:] if len(speed_history) >= 10 else speed_history
        
        avg_speed = statistics.mean(recent_speeds) if recent_speeds else 0
        speed_stability = self._calculate_stability(recent_speeds)
        
        avg_latency = statistics.mean(latency_samples) if latency_samples else 100
        latency_stability = self._calculate_stability(latency_samples) if latency_samples else 1
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ú©ÛŒÙÛŒØª (0-100)
        quality_score = self._calculate_quality_score(
            avg_speed, speed_stability, avg_latency, latency_stability, error_rate
        )
        
        # ØªØ¹ÛŒÛŒÙ† Ú©ÛŒÙÛŒØª Ø´Ø¨Ú©Ù‡
        if quality_score >= 90:
            quality = NetworkQuality.EXCELLENT
            recommendation = "Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø­Ø¯Ø§Ú©Ø«Ø± chunk size Ùˆ Ù…ÙˆØ§Ø²ÛŒâ€ŒØ³Ø§Ø²ÛŒ"
        elif quality_score >= 70:
            quality = NetworkQuality.GOOD
            recommendation = "Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² compression Ù…ØªÙˆØ³Ø· Ùˆ chunk size Ø¨Ø§Ù„Ø§"
        elif quality_score >= 50:
            quality = NetworkQuality.FAIR
            recommendation = "ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù…ØªØ¹Ø§Ø¯Ù„"
        elif quality_score >= 30:
            quality = NetworkQuality.POOR
            recommendation = "Ú©Ø§Ù‡Ø´ chunk size Ùˆ ØºÛŒØ±ÙØ¹Ø§Ù„ Ú©Ø±Ø¯Ù† compression"
        else:
            quality = NetworkQuality.UNSTABLE
            recommendation = "Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² chunk size Ú©ÙˆÚ†Ú© Ùˆ retry Ù…ØªØ¹Ø¯Ø¯"
        
        # Ø°Ø®ÛŒØ±Ù‡ ØªØ§Ø±ÛŒØ®Ú†Ù‡
        self.network_quality_history.append(quality)
        if len(self.network_quality_history) > 20:
            self.network_quality_history.pop(0)
        
        # ØªÙ†Ø¸ÛŒÙ… chunk size
        self.current_chunk_size = self._determine_optimal_chunk_size(
            quality, avg_speed, speed_stability
        )
        
        # ØªÙˆÙ„ÛŒØ¯ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¨Ù‡ÛŒÙ†Ù‡
        optimization = {
            'network_quality': quality,
            'quality_score': quality_score,
            'optimal_chunk_size': self.current_chunk_size,
            'recommendation': recommendation,
            'compression_level': self._determine_compression_level(quality_score),
            'parallel_connections': self._determine_parallel_connections(quality_score),
            'retry_count': self._determine_retry_count(error_rate),
            'timeout': self._determine_timeout(avg_latency),
            'buffer_size': self._determine_buffer_size(avg_speed),
            'metrics': {
                'average_speed': avg_speed,
                'speed_stability': speed_stability,
                'average_latency': avg_latency,
                'latency_stability': latency_stability,
                'error_rate': error_rate
            }
        }
        
        # Ø°Ø®ÛŒØ±Ù‡ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„
        if time.time() - self.last_optimization_time >= self.optimization_interval:
            self.optimization_history.append({
                'timestamp': time.time(),
                **optimization
            })
            self.last_optimization_time = time.time()
            
            # Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† ØªØ§Ø±ÛŒØ®Ú†Ù‡
            if len(self.optimization_history) > 100:
                self.optimization_history.pop(0)
        
        return optimization
    
    def _calculate_quality_score(self, avg_speed: float, speed_stability: float,
                               avg_latency: float, latency_stability: float,
                               error_rate: float) -> float:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ú©ÛŒÙÛŒØª Ø´Ø¨Ú©Ù‡"""
        
        # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø³Ø±Ø¹Øª (0-40 Ø§Ù…ØªÛŒØ§Ø²)
        speed_score = min(40, (avg_speed / (1024 * 1024)) * 20)  # 2MB/s = 40 Ø§Ù…ØªÛŒØ§Ø²
        
        # Ù¾Ø§ÛŒØ¯Ø§Ø±ÛŒ Ø³Ø±Ø¹Øª (0-20 Ø§Ù…ØªÛŒØ§Ø²)
        stability_score = speed_stability * 20
        
        # ØªØ£Ø®ÛŒØ± (0-25 Ø§Ù…ØªÛŒØ§Ø²)
        latency_score = max(0, 25 - (avg_latency / 100))  # Ù‡Ø± 100ms ÛŒÚ© Ø§Ù…ØªÛŒØ§Ø² Ú©Ù…
        
        # Ù¾Ø§ÛŒØ¯Ø§Ø±ÛŒ ØªØ£Ø®ÛŒØ± (0-15 Ø§Ù…ØªÛŒØ§Ø²)
        latency_stability_score = (1 - min(1, latency_stability)) * 15
        
        # Ù†Ø±Ø® Ø®Ø·Ø§ (Ú©Ø³ÙˆØ±Ø§Øª)
        error_penalty = error_rate * 100
        
        total = speed_score + stability_score + latency_score + latency_stability_score - error_penalty
        
        return max(0, min(100, total))
    
    def _calculate_stability(self, values: List[float]) -> float:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù¾Ø§ÛŒØ¯Ø§Ø±ÛŒ (Ø¶Ø±ÛŒØ¨ ØªØºÛŒÛŒØ±Ø§Øª Ù…Ø¹Ú©ÙˆØ³)"""
        if len(values) < 2:
            return 1.0
        
        mean_val = statistics.mean(values)
        if mean_val == 0:
            return 0.0
        
        std_dev = statistics.stdev(values)
        cv = std_dev / mean_val
        
        # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ù¾Ø§ÛŒØ¯Ø§Ø±ÛŒ (1=Ú©Ø§Ù…Ù„Ø§Ù‹ Ù¾Ø§ÛŒØ¯Ø§Ø±ØŒ 0=Ú©Ø§Ù…Ù„Ø§Ù‹ Ù†Ø§Ù¾Ø§ÛŒØ¯Ø§Ø±)
        return 1 / (1 + cv)
    
    def _determine_optimal_chunk_size(self, quality: NetworkQuality, 
                                    avg_speed: float, stability: float) -> int:
        """ØªØ¹ÛŒÛŒÙ† Ø§Ù†Ø¯Ø§Ø²Ù‡ chunk Ø¨Ù‡ÛŒÙ†Ù‡"""
        
        base_size = self.chunk_sizes[quality.value]
        
        # ØªÙ†Ø¸ÛŒÙ… Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³Ø±Ø¹Øª
        if avg_speed > 10 * 1024 * 1024:  # Ø¨ÛŒØ´ Ø§Ø² 10MB/s
            size_multiplier = 2.0
        elif avg_speed > 5 * 1024 * 1024:  # Ø¨ÛŒØ´ Ø§Ø² 5MB/s
            size_multiplier = 1.5
        elif avg_speed > 1 * 1024 * 1024:  # Ø¨ÛŒØ´ Ø§Ø² 1MB/s
            size_multiplier = 1.2
        else:
            size_multiplier = 1.0
        
        # ØªÙ†Ø¸ÛŒÙ… Ø¨Ø± Ø§Ø³Ø§Ø³ Ù¾Ø§ÛŒØ¯Ø§Ø±ÛŒ
        stability_multiplier = 0.5 + stability  # 0.5-1.5
        
        final_size = int(base_size * size_multiplier * stability_multiplier)
        
        # Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§
        min_size = 1024  # 1KB
        max_size = 4 * 1024 * 1024  # 4MB
        
        return max(min_size, min(max_size, final_size))
    
    def _determine_compression_level(self, quality_score: float) -> int:
        """ØªØ¹ÛŒÛŒÙ† Ø³Ø·Ø­ ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ"""
        if quality_score < 30:
            return 0  # Ø¨Ø¯ÙˆÙ† ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ
        elif quality_score < 60:
            return 1  # ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú©Ù…
        elif quality_score < 80:
            return 3  # ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙˆØ³Ø·
        else:
            return 6  # ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø§Ù„Ø§
    
    def _determine_parallel_connections(self, quality_score: float) -> int:
        """ØªØ¹ÛŒÛŒÙ† ØªØ¹Ø¯Ø§Ø¯ Ø§ØªØµØ§Ù„Ø§Øª Ù…ÙˆØ§Ø²ÛŒ"""
        if quality_score < 20:
            return 1
        elif quality_score < 50:
            return 2
        elif quality_score < 70:
            return 3
        elif quality_score < 85:
            return 4
        else:
            return 5
    
    def _determine_retry_count(self, error_rate: float) -> int:
        """ØªØ¹ÛŒÛŒÙ† ØªØ¹Ø¯Ø§Ø¯ ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯"""
        if error_rate > 0.1:  # Ø¨ÛŒØ´ Ø§Ø² 10% Ø®Ø·Ø§
            return 5
        elif error_rate > 0.05:  # Ø¨ÛŒØ´ Ø§Ø² 5% Ø®Ø·Ø§
            return 3
        elif error_rate > 0.01:  # Ø¨ÛŒØ´ Ø§Ø² 1% Ø®Ø·Ø§
            return 2
        else:
            return 1
    
    def _determine_timeout(self, avg_latency: float) -> float:
        """ØªØ¹ÛŒÛŒÙ† Ø²Ù…Ø§Ù† ØªØ§ÛŒÙ…â€ŒØ§ÙˆØª"""
        return max(10, avg_latency * 10)  # Ø­Ø¯Ø§Ù‚Ù„ 10 Ø«Ø§Ù†ÛŒÙ‡
    
    def _determine_buffer_size(self, avg_speed: float) -> int:
        """ØªØ¹ÛŒÛŒÙ† Ø§Ù†Ø¯Ø§Ø²Ù‡ Ø¨Ø§ÙØ±"""
        # Ø¨Ø§ÙØ± Ø¨Ø±Ø§ÛŒ 100ms Ø§Ø² Ø¯Ø§Ø¯Ù‡
        buffer_for_100ms = int(avg_speed * 0.1)
        
        # Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§
        min_buffer = 4 * 1024  # 4KB
        max_buffer = 16 * 1024 * 1024  # 16MB
        
        return max(min_buffer, min(max_buffer, buffer_for_100ms))
    
    def _get_default_optimization(self) -> Dict:
        """Ø¯Ø±ÛŒØ§ÙØª ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶"""
        return {
            'network_quality': NetworkQuality.FAIR,
            'quality_score': 50,
            'optimal_chunk_size': self.chunk_sizes['good'],
            'recommendation': "Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶",
            'compression_level': 2,
            'parallel_connections': 2,
            'retry_count': 3,
            'timeout': 30,
            'buffer_size': 64 * 1024,
            'metrics': {
                'average_speed': 0,
                'speed_stability': 0,
                'average_latency': 100,
                'latency_stability': 0,
                'error_rate': 0
            }
        }
    
    def generate_optimization_report(self, optimization: Dict) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ"""
        quality_emojis = {
            NetworkQuality.EXCELLENT: "ğŸš€",
            NetworkQuality.GOOD: "ğŸ‘",
            NetworkQuality.FAIR: "ğŸ“¶",
            NetworkQuality.POOR: "ğŸŒ",
            NetworkQuality.UNSTABLE: "ğŸŒªï¸"
        }
        
        emoji = quality_emojis.get(optimization['network_quality'], "â“")
        
        lines = []
        lines.append(f"{emoji} {ProgressUI.COLORS['bold']}Ú¯Ø²Ø§Ø±Ø´ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¨Ú©Ù‡{ProgressUI.COLORS['reset']}")
        lines.append("=" * 50)
        
        lines.append(f"ğŸ“Š Ú©ÛŒÙÛŒØª Ø´Ø¨Ú©Ù‡: {optimization['network_quality'].value} "
                    f"({optimization['quality_score']:.1f}/100)")
        
        lines.append(f"ğŸ”§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¨Ù‡ÛŒÙ†Ù‡:")
        lines.append(f"  â”œâ”€ Chunk Size: {ProgressUI.format_size(optimization['optimal_chunk_size'])}")
        lines.append(f"  â”œâ”€ Compression: Level {optimization['compression_level']}")
        lines.append(f"  â”œâ”€ Ø§ØªØµØ§Ù„Ø§Øª Ù…ÙˆØ§Ø²ÛŒ: {optimization['parallel_connections']}")
        lines.append(f"  â”œâ”€ ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯: {optimization['retry_count']}")
        lines.append(f"  â”œâ”€ Timeout: {optimization['timeout']} Ø«Ø§Ù†ÛŒÙ‡")
        lines.append(f"  â””â”€ Buffer: {ProgressUI.format_size(optimization['buffer_size'])}")
        
        lines.append("")
        lines.append(f"ğŸ’¡ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯: {optimization['recommendation']}")
        
        return "\n".join(lines)

# ================ RealTimeAnalytics ================

class RealTimeAnalytics:
    """Ø¢Ù†Ø§Ù„ÛŒØ² Ù„Ø­Ø¸Ù‡â€ŒØ§ÛŒ Ùˆ Ú¯Ø²Ø§Ø±Ø´â€ŒÚ¯ÛŒØ±ÛŒ"""
    
    def __init__(self):
        self.metrics_buffer: List[Dict] = []
        self.alerts: List[Dict] = []
        self.anomalies: List[Dict] = []
        self.max_buffer_size = 1000
        self.alert_rules = self._get_default_alert_rules()
    
    def track_metric(self, name: str, value: float, 
                    tags: Optional[Dict] = None, timestamp: Optional[float] = None):
        """Ø±Ø¯ÛŒØ§Ø¨ÛŒ Ù…ØªØ±ÛŒÚ©"""
        metric = {
            'timestamp': timestamp or time.time(),
            'name': name,
            'value': value,
            'tags': tags or {}
        }
        
        self.metrics_buffer.append(metric)
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø¢Ù„Ø±Øª
        self._check_alerts(metric)
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ù†Ø§Ù‡Ù†Ø¬Ø§Ø±ÛŒ
        if self._is_anomaly(metric):
            self.anomalies.append({
                **metric,
                'detected_at': time.time(),
                'severity': self._calculate_anomaly_severity(metric)
            })
        
        # Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø§Ù†Ø¯Ø§Ø²Ù‡ Ø¨Ø§ÙØ±
        if len(self.metrics_buffer) > self.max_buffer_size:
            self.metrics_buffer = self.metrics_buffer[-self.max_buffer_size:]
    
    def _check_alerts(self, metric: Dict):
        """Ø¨Ø±Ø±Ø³ÛŒ Ù‚ÙˆØ§Ù†ÛŒÙ† Ø¢Ù„Ø±Øª"""
        for rule in self.alert_rules:
            if rule['metric'] == metric['name']:
                if rule['condition'](metric['value']):
                    alert = {
                        'id': f"alert_{len(self.alerts)}_{int(time.time())}",
                        'metric': metric['name'],
                        'value': metric['value'],
                        'threshold': rule['threshold'],
                        'message': rule['message'],
                        'severity': rule['severity'],
                        'timestamp': metric['timestamp'],
                        'triggered_at': time.time()
                    }
                    
                    # Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø¢Ù„Ø±Øªâ€ŒÙ‡Ø§ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ
                    if not self._is_duplicate_alert(alert):
                        self.alerts.append(alert)
    
    def _is_anomaly(self, metric: Dict) -> bool:
        """ØªØ´Ø®ÛŒØµ Ù†Ø§Ù‡Ù†Ø¬Ø§Ø±ÛŒ"""
        # ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø³Ø±Ø¹Øª
        if metric['name'] != 'transfer_speed':
            return False
        
        # Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø­Ø¯Ø§Ù‚Ù„ Ø¯Ø§Ø¯Ù‡
        if len(self.metrics_buffer) < 20:
            return False
        
        # Ú¯Ø±ÙØªÙ† ØªØ§Ø±ÛŒØ®Ú†Ù‡
        speed_history = [m['value'] for m in self.metrics_buffer 
                        if m['name'] == 'transfer_speed']
        
        if len(speed_history) < 10:
            return False
        
        # ØªØ´Ø®ÛŒØµ Ø¨Ø§ Z-score
        recent_speeds = speed_history[-10:]
        mean_speed = statistics.mean(recent_speeds[:-1])
        std_speed = statistics.stdev(recent_speeds[:-1]) if len(recent_speeds) > 2 else 0
        
        if std_speed == 0:
            return False
        
        z_score = abs(recent_speeds[-1] - mean_speed) / std_speed
        
        # Ø§Ú¯Ø± Z-score Ø¨ÛŒØ´ØªØ± Ø§Ø² 3 Ø¨Ø§Ø´Ø¯ (Ø®Ø§Ø±Ø¬ Ø§Ø² 3 Ø§Ù†Ø­Ø±Ø§Ù Ù…Ø¹ÛŒØ§Ø±)
        return z_score > 3.0
    
    def generate_performance_report(self, window_minutes: int = 5) -> Dict:
        """ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ Ø¹Ù…Ù„Ú©Ø±Ø¯"""
        window_start = time.time() - (window_minutes * 60)
        
        # ÙÛŒÙ„ØªØ± Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ù¾Ù†Ø¬Ø±Ù‡ Ø²Ù…Ø§Ù†ÛŒ
        recent_metrics = [
            m for m in self.metrics_buffer 
            if m['timestamp'] >= window_start
        ]
        
        # Ú¯Ø±ÙˆÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§
        metrics_by_name = {}
        for metric in recent_metrics:
            if metric['name'] not in metrics_by_name:
                metrics_by_name[metric['name']] = []
            metrics_by_name[metric['name']].append(metric['value'])
        
        # ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
        analyses = {}
        
        for name, values in metrics_by_name.items():
            if not values:
                continue
            
            analyses[name] = {
                'count': len(values),
                'min': min(values),
                'max': max(values),
                'mean': statistics.mean(values),
                'median': statistics.median(values),
                'std_dev': statistics.stdev(values) if len(values) > 1 else 0,
                'trend': self._calculate_trend(values),
                'percentiles': {
                    '25': np.percentile(values, 25) if values else 0,
                    '50': np.percentile(values, 50) if values else 0,
                    '75': np.percentile(values, 75) if values else 0,
                    '95': np.percentile(values, 95) if values else 0
                }
            }
        
        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ bottlenecks
        bottlenecks = self._detect_bottlenecks(analyses)
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ú©Ø§Ø±Ø§ÛŒÛŒ
        efficiency = self._calculate_efficiency(analyses)
        
        # ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§
        recommendations = self._generate_recommendations(analyses, bottlenecks)
        
        return {
            'time_window': f"{window_minutes} Ø¯Ù‚ÛŒÙ‚Ù‡",
            'metric_count': len(recent_metrics),
            'unique_metrics': len(metrics_by_name),
            'analyses': analyses,
            'bottlenecks': bottlenecks,
            'efficiency_score': efficiency['score'],
            'efficiency_rating': efficiency['rating'],
            'recommendations': recommendations,
            'alerts': self.alerts[-10:],  # Ø¢Ø®Ø±ÛŒÙ† 10 Ø¢Ù„Ø±Øª
            'anomalies': self.anomalies[-5:],  # Ø¢Ø®Ø±ÛŒÙ† 5 Ù†Ø§Ù‡Ù†Ø¬Ø§Ø±ÛŒ
            'summary_stats': {
                'start_time': window_start,
                'end_time': time.time(),
                'duration_minutes': window_minutes
            }
        }
    
    def _get_default_alert_rules(self) -> List[Dict]:
        """Ù‚ÙˆØ§Ù†ÛŒÙ† Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¢Ù„Ø±Øª"""
        return [
            {
                'metric': 'transfer_speed',
                'condition': lambda x: x < 1024,  # Ú©Ù…ØªØ± Ø§Ø² 1KB/s
                'threshold': 1024,
                'message': 'Ø³Ø±Ø¹Øª Ø§Ù†ØªÙ‚Ø§Ù„ Ø¨Ø³ÛŒØ§Ø± Ù¾Ø§ÛŒÛŒÙ† Ø§Ø³Øª',
                'severity': 'warning'
            },
            {
                'metric': 'transfer_speed',
                'condition': lambda x: x == 0,
                'threshold': 0,
                'message': 'Ø§Ù†ØªÙ‚Ø§Ù„ Ù…ØªÙˆÙ‚Ù Ø´Ø¯Ù‡ Ø§Ø³Øª',
                'severity': 'critical'
            },
            {
                'metric': 'error_rate',
                'condition': lambda x: x > 0.1,  # Ø¨ÛŒØ´ Ø§Ø² 10% Ø®Ø·Ø§
                'threshold': 0.1,
                'message': 'Ù†Ø±Ø® Ø®Ø·Ø§ Ø¨Ø³ÛŒØ§Ø± Ø¨Ø§Ù„Ø§ Ø§Ø³Øª',
                'severity': 'error'
            },
            {
                'metric': 'latency',
                'condition': lambda x: x > 5000,  # Ø¨ÛŒØ´ Ø§Ø² 5 Ø«Ø§Ù†ÛŒÙ‡
                'threshold': 5000,
                'message': 'ØªØ£Ø®ÛŒØ± Ø´Ø¨Ú©Ù‡ Ø¨Ø³ÛŒØ§Ø± Ø¨Ø§Ù„Ø§ Ø§Ø³Øª',
                'severity': 'warning'
            }
        ]
    
    def _is_duplicate_alert(self, alert: Dict, cooldown: int = 60) -> bool:
        """Ø¨Ø±Ø±Ø³ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ Ø¨ÙˆØ¯Ù† Ø¢Ù„Ø±Øª"""
        for existing_alert in self.alerts[-10:]:  # Ø¨Ø±Ø±Ø³ÛŒ Ø¢Ø®Ø±ÛŒÙ† 10 Ø¢Ù„Ø±Øª
            if (existing_alert['metric'] == alert['metric'] and
                existing_alert['severity'] == alert['severity'] and
                alert['timestamp'] - existing_alert['timestamp'] < cooldown):
                return True
        return False
    
    def _calculate_trend(self, values: List[float]) -> str:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø±ÙˆÙ†Ø¯"""
        if len(values) < 2:
            return "Ø«Ø§Ø¨Øª"
        
        # Ø±Ú¯Ø±Ø³ÛŒÙˆÙ† Ø®Ø·ÛŒ Ø³Ø§Ø¯Ù‡
        x = np.arange(len(values))
        y = np.array(values)
        
        try:
            slope = np.polyfit(x, y, 1)[0]
            
            if slope > 0.01:
                return "ØµØ¹ÙˆØ¯ÛŒ"
            elif slope < -0.01:
                return "Ù†Ø²ÙˆÙ„ÛŒ"
            else:
                return "Ø«Ø§Ø¨Øª"
        except:
            return "Ù†Ø§Ù…Ø´Ø®Øµ"
    
    def _detect_bottlenecks(self, analyses: Dict) -> List[Dict]:
        """Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ bottlenecks"""
        bottlenecks = []
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø³Ø±Ø¹Øª Ø´Ø¨Ú©Ù‡
        if 'transfer_speed' in analyses:
            speed_analysis = analyses['transfer_speed']
            if speed_analysis['mean'] < 100 * 1024:  # Ú©Ù…ØªØ± Ø§Ø² 100KB/s
                bottlenecks.append({
                    'type': 'network_speed',
                    'severity': 'high',
                    'metric': 'transfer_speed',
                    'current_value': speed_analysis['mean'],
                    'recommended_min': 1024 * 1024,  # 1MB/s
                    'description': 'Ø³Ø±Ø¹Øª Ø´Ø¨Ú©Ù‡ Ø¨Ø³ÛŒØ§Ø± Ù¾Ø§ÛŒÛŒÙ† Ø§Ø³Øª'
                })
        
        # Ø¨Ø±Ø±Ø³ÛŒ ØªØ£Ø®ÛŒØ±
        if 'latency' in analyses:
            latency_analysis = analyses['latency']
            if latency_analysis['mean'] > 1000:  # Ø¨ÛŒØ´ Ø§Ø² 1 Ø«Ø§Ù†ÛŒÙ‡
                bottlenecks.append({
                    'type': 'high_latency',
                    'severity': 'medium',
                    'metric': 'latency',
                    'current_value': latency_analysis['mean'],
                    'recommended_max': 100,
                    'description': 'ØªØ£Ø®ÛŒØ± Ø´Ø¨Ú©Ù‡ Ø¨Ø³ÛŒØ§Ø± Ø¨Ø§Ù„Ø§ Ø§Ø³Øª'
                })
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ù†Ø±Ø® Ø®Ø·Ø§
        if 'error_rate' in analyses:
            error_analysis = analyses['error_rate']
            if error_analysis['mean'] > 0.05:  # Ø¨ÛŒØ´ Ø§Ø² 5% Ø®Ø·Ø§
                bottlenecks.append({
                    'type': 'high_error_rate',
                    'severity': 'high',
                    'metric': 'error_rate',
                    'current_value': error_analysis['mean'],
                    'recommended_max': 0.01,
                    'description': 'Ù†Ø±Ø® Ø®Ø·Ø§ Ø¨Ø³ÛŒØ§Ø± Ø¨Ø§Ù„Ø§ Ø§Ø³Øª'
                })
        
        return bottlenecks
    
    def _calculate_efficiency(self, analyses: Dict) -> Dict:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ú©Ø§Ø±Ø§ÛŒÛŒ"""
        score = 50  # Ù†Ù…Ø±Ù‡ Ù¾Ø§ÛŒÙ‡
        
        factors = []
        
        # Ø¹Ø§Ù…Ù„ Ø³Ø±Ø¹Øª
        if 'transfer_speed' in analyses:
            speed = analyses['transfer_speed']['mean']
            speed_score = min(100, (speed / (5 * 1024 * 1024)) * 100)  # 5MB/s = 100
            factors.append(('speed', speed_score, 0.4))
        
        # Ø¹Ø§Ù…Ù„ Ù¾Ø§ÛŒØ¯Ø§Ø±ÛŒ
        if 'transfer_speed' in analyses:
            stability = 1 - min(1, analyses['transfer_speed']['std_dev'] / 
                              max(1, analyses['transfer_speed']['mean']))
            stability_score = stability * 100
            factors.append(('stability', stability_score, 0.3))
        
        # Ø¹Ø§Ù…Ù„ Ø®Ø·Ø§
        if 'error_rate' in analyses:
            error_rate = analyses['error_rate']['mean']
            error_score = max(0, 100 - (error_rate * 1000))
            factors.append(('error', error_score, 0.2))
        
        # Ø¹Ø§Ù…Ù„ ØªØ£Ø®ÛŒØ±
        if 'latency' in analyses:
            latency = analyses['latency']['mean']
            latency_score = max(0, 100 - (latency / 10))
            factors.append(('latency', latency_score, 0.1))
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ù…Ø±Ù‡ Ù†Ù‡Ø§ÛŒÛŒ
        if factors:
            weighted_sum = sum(score * weight for _, score, weight in factors)
            total_weight = sum(weight for _, _, weight in factors)
            score = weighted_sum / total_weight if total_weight > 0 else 50
        
        # ØªØ¹ÛŒÛŒÙ† Ø±ØªØ¨Ù‡
        if score >= 90:
            rating = "Ø¹Ø§Ù„ÛŒ"
        elif score >= 70:
            rating = "Ø®ÙˆØ¨"
        elif score >= 50:
            rating = "Ù…ØªÙˆØ³Ø·"
        elif score >= 30:
            rating = "Ø¶Ø¹ÛŒÙ"
        else:
            rating = "Ø¨Ø³ÛŒØ§Ø± Ø¶Ø¹ÛŒÙ"
        
        return {
            'score': score,
            'rating': rating,
            'factors': [{'name': name, 'score': s, 'weight': w} 
                       for name, s, w in factors]
        }
    
    def _generate_recommendations(self, analyses: Dict, bottlenecks: List[Dict]) -> List[str]:
        """ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§"""
        recommendations = []
        
        for bottleneck in bottlenecks:
            if bottleneck['type'] == 'network_speed':
                recommendations.append(
                    "Ø¨Ø±Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ø³Ø±Ø¹Øª Ø´Ø¨Ú©Ù‡:\n"
                    "  â€¢ Ø§Ø² Ø§ØªØµØ§Ù„ Ú©Ø§Ø¨Ù„ÛŒ Ø¨Ù‡ Ø¬Ø§ÛŒ Wi-Fi Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯\n"
                    "  â€¢ Ø³Ø§ÛŒØ± Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø±Ø§ Ù…ØªÙˆÙ‚Ù Ú©Ù†ÛŒØ¯\n"
                    "  â€¢ Ø³Ø±ÙˆÛŒØ³ Ø§ÛŒÙ†ØªØ±Ù†Øª Ø®ÙˆØ¯ Ø±Ø§ Ø§Ø±ØªÙ‚Ø§ Ø¯Ù‡ÛŒØ¯"
                )
            elif bottleneck['type'] == 'high_latency':
                recommendations.append(
                    "Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù‡Ø´ ØªØ£Ø®ÛŒØ± Ø´Ø¨Ú©Ù‡:\n"
                    "  â€¢ Ø¨Ù‡ Ø³Ø±ÙˆØ± Ù†Ø²Ø¯ÛŒÚ©â€ŒØªØ±ÛŒ Ù…ØªØµÙ„ Ø´ÙˆÛŒØ¯\n"
                    "  â€¢ Ø§Ø² VPN Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ú©Ù†ÛŒØ¯\n"
                    "  â€¢ ÙØ§ÛŒØ±ÙˆØ§Ù„ Ùˆ Ø¢Ù†ØªÛŒâ€ŒÙˆÛŒØ±ÙˆØ³ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯"
                )
            elif bottleneck['type'] == 'high_error_rate':
                recommendations.append(
                    "Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù‡Ø´ Ø®Ø·Ø§Ù‡Ø§:\n"
                    "  â€¢ Ø§ØªØµØ§Ù„ Ø´Ø¨Ú©Ù‡ Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯\n"
                    "  â€¢ ØªÙ†Ø¸ÛŒÙ…Ø§Øª retry Ø±Ø§ Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ù‡ÛŒØ¯\n"
                    "  â€¢ Ø§Ø² Ø§ØªØµØ§Ù„ Ù¾Ø§ÛŒØ¯Ø§Ø±ØªØ±ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯"
                )
        
        # ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø¹Ù…ÙˆÙ…ÛŒ
        if 'transfer_speed' in analyses:
            speed = analyses['transfer_speed']['mean']
            if speed < 1024 * 1024:  # Ú©Ù…ØªØ± Ø§Ø² 1MB/s
                recommendations.append(
                    "Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯: Ø§Ø² Ø­Ø§Ù„Øª ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù‡Ø´ Ø­Ø¬Ù… Ø¯Ø§Ø¯Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯"
                )
        
        if len(recommendations) == 0:
            recommendations.append("Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø·Ù„ÙˆØ¨ Ø§Ø³Øª. ØªÙ†Ø¸ÛŒÙ…Ø§Øª ÙØ¹Ù„ÛŒ Ø±Ø§ Ø­ÙØ¸ Ú©Ù†ÛŒØ¯.")
        
        return recommendations
    
    def create_analytics_dashboard(self, report: Dict) -> str:
        """Ø§ÛŒØ¬Ø§Ø¯ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ø¢Ù†Ø§Ù„ÛŒØªÛŒÚ©Ø³"""
        lines = []
        ui = ProgressUI()
        
        lines.append(f"{ui.COLORS['bold']}ğŸ“ˆ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ø¢Ù†Ø§Ù„ÛŒØªÛŒÚ©Ø³ Ù„Ø­Ø¸Ù‡â€ŒØ§ÛŒ{ui.COLORS['reset']}")
        lines.append("=" * 60)
        
        # Ø®Ù„Ø§ØµÙ‡
        lines.append(f"ğŸ“Š Ø®Ù„Ø§ØµÙ‡ Ø¹Ù…Ù„Ú©Ø±Ø¯:")
        lines.append(f"  â”œâ”€ Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ: {report['time_window']}")
        lines.append(f"  â”œâ”€ ØªØ¹Ø¯Ø§Ø¯ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§: {report['metric_count']}")
        lines.append(f"  â”œâ”€ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ù…Ù†Ø­ØµØ±Ø¨ÙØ±Ø¯: {report['unique_metrics']}")
        lines.append(f"  â””â”€ Ø§Ù…ØªÛŒØ§Ø² Ú©Ø§Ø±Ø§ÛŒÛŒ: {report['efficiency_score']:.1f}/100 "
                    f"({report['efficiency_rating']})")
        lines.append("")
        
        # Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ
        if 'transfer_speed' in report['analyses']:
            speed_analysis = report['analyses']['transfer_speed']
            lines.append(f"âš¡ Ø³Ø±Ø¹Øª Ø§Ù†ØªÙ‚Ø§Ù„:")
            lines.append(f"  â”œâ”€ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†: {ui.format_speed(speed_analysis['mean'])}")
            lines.append(f"  â”œâ”€ Ù…ÛŒØ§Ù†Ù‡: {ui.format_speed(speed_analysis['median'])}")
            lines.append(f"  â”œâ”€ Ù…Ø­Ø¯ÙˆØ¯Ù‡: {ui.format_speed(speed_analysis['min'])} - "
                        f"{ui.format_speed(speed_analysis['max'])}")
            lines.append(f"  â””â”€ Ø±ÙˆÙ†Ø¯: {speed_analysis['trend']}")
            lines.append("")
        
        # bottlenecks
        if report['bottlenecks']:
            lines.append(f"âš  bottlenecks Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡:")
            for bottleneck in report['bottlenecks']:
                severity_icon = {'high': 'ğŸ”´', 'medium': 'ğŸŸ¡', 'low': 'ğŸŸ¢'}.get(
                    bottleneck['severity'], 'âšª'
                )
                lines.append(f"  {severity_icon} {bottleneck['description']}")
            lines.append("")
        
        # ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§
        if report['recommendations']:
            lines.append(f"ğŸ’¡ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§:")
            for i, recommendation in enumerate(report['recommendations'][:3], 1):
                lines.append(f"  {i}. {recommendation}")
            lines.append("")
        
        # Ø¢Ù„Ø±Øªâ€ŒÙ‡Ø§
        if report['alerts']:
            lines.append(f"ğŸš¨ Ø¢Ù„Ø±Øªâ€ŒÙ‡Ø§ÛŒ Ø§Ø®ÛŒØ±:")
            for alert in report['alerts'][-3:]:
                time_ago = ui.format_time(time.time() - alert['timestamp'])
                severity_icon = {'critical': 'ğŸ”´', 'error': 'ğŸŸ ', 'warning': 'ğŸŸ¡'}.get(
                    alert['severity'], 'âšª'
                )
                lines.append(f"  {severity_icon} [{time_ago} Ù¾ÛŒØ´] {alert['message']}")
        
        return "\n".join(lines)

# ================ GamificationEngine ================

class GamificationEngine:
    """Ù…ÙˆØªÙˆØ± Ø¨Ø§Ø²ÛŒâ€ŒØ³Ø§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ¬Ø±Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø±ÛŒ Ø¨Ù‡ØªØ±"""
    
    def __init__(self):
        self.user_stats = {
            'level': 1,
            'xp': 0,
            'total_xp': 0,
            'total_transfers': 0,
            'total_data': 0,
            'achievements': [],
            'streak_days': 0,
            'last_activity': time.time(),
            'session_start': time.time()
        }
        
        self.achievements_db = self._load_achievements()
        self.levels_db = self._load_levels()
        
    def _load_achievements(self) -> List[Dict]:
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø³ØªØ§ÙˆØ±Ø¯Ù‡Ø§"""
        return [
            {
                'id': 'speed_demon',
                'name': 'Ø´ÛŒØ·Ø§Ù† Ø³Ø±Ø¹Øª ğŸš€',
                'description': 'Ø±Ø³ÛŒØ¯Ù† Ø¨Ù‡ Ø³Ø±Ø¹Øª Ø¨ÛŒØ´ Ø§Ø² 50MB/s',
                'condition': lambda stats: stats.get('max_speed', 0) > 50 * 1024 * 1024,
                'xp_reward': 100,
                'icon': 'ğŸš€'
            },
            {
                'id': 'marathon',
                'name': 'Ù…Ø§Ø±Ø§ØªÙ† Ø§Ù†ØªÙ‚Ø§Ù„ ğŸ“',
                'description': 'Ø§Ù†ØªÙ‚Ø§Ù„ Ø¨ÛŒØ´ Ø§Ø² 100 ÙØ§ÛŒÙ„',
                'condition': lambda stats: stats.get('total_transfers', 0) >= 100,
                'xp_reward': 150,
                'icon': 'ğŸ“'
            },
            {
                'id': 'data_hoarder',
                'name': 'Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø² Ø¯Ø§Ø¯Ù‡ ğŸ’¾',
                'description': 'Ø§Ù†ØªÙ‚Ø§Ù„ Ø¨ÛŒØ´ Ø§Ø² 1TB Ø¯Ø§Ø¯Ù‡',
                'condition': lambda stats: stats.get('total_data', 0) >= 1024 ** 4,
                'xp_reward': 500,
                'icon': 'ğŸ’¾'
            },
            {
                'id': 'perfectionist',
                'name': 'Ú©Ù…Ø§Ù„â€ŒÚ¯Ø±Ø§ â­',
                'description': 'Ø§ØªÙ…Ø§Ù… Ø§Ù†ØªÙ‚Ø§Ù„ Ø¨Ø§ 0 Ø®Ø·Ø§',
                'condition': lambda stats: stats.get('error_count', 0) == 0,
                'xp_reward': 50,
                'icon': 'â­'
            },
            {
                'id': 'night_owl',
                'name': 'Ø¬ØºØ¯ Ø´Ø¨ ğŸ¦‰',
                'description': 'Ø§ØªÙ…Ø§Ù… Ø§Ù†ØªÙ‚Ø§Ù„ Ø¨ÛŒÙ† Ø³Ø§Ø¹Øª 12 Ø´Ø¨ ØªØ§ 5 ØµØ¨Ø­',
                'condition': lambda stats: stats.get('completed_at_hour', 0) in [0, 1, 2, 3, 4],
                'xp_reward': 75,
                'icon': 'ğŸ¦‰'
            },
            {
                'id': 'weekend_warrior',
                'name': 'Ø¬Ù†Ú¯Ø¬ÙˆÛŒ Ø¢Ø®Ø± Ù‡ÙØªÙ‡ ğŸ¯',
                'description': 'Ø§ØªÙ…Ø§Ù… 10 Ø§Ù†ØªÙ‚Ø§Ù„ Ø¯Ø± ÛŒÚ© Ø±ÙˆØ² Ø¢Ø®Ø± Ù‡ÙØªÙ‡',
                'condition': lambda stats: stats.get('weekend_transfers', 0) >= 10,
                'xp_reward': 200,
                'icon': 'ğŸ¯'
            },
            {
                'id': 'early_bird',
                'name': 'Ø³Ø­Ø±Ø®ÛŒØ² ğŸŒ…',
                'description': 'Ø¢ØºØ§Ø² Ø§Ù†ØªÙ‚Ø§Ù„ Ù‚Ø¨Ù„ Ø§Ø² Ø³Ø§Ø¹Øª 7 ØµØ¨Ø­',
                'condition': lambda stats: stats.get('started_at_hour', 0) < 7,
                'xp_reward': 60,
                'icon': 'ğŸŒ…'
            },
            {
                'id': 'consistent',
                'name': 'Ù…Ù†Ø¸Ù… ğŸ“…',
                'description': '7 Ø±ÙˆØ² Ù…ØªÙˆØ§Ù„ÛŒ ÙØ¹Ø§Ù„ÛŒØª',
                'condition': lambda stats: stats.get('streak_days', 0) >= 7,
                'xp_reward': 300,
                'icon': 'ğŸ“…'
            },
            {
                'id': 'speedster',
                'name': 'Ø³Ø±Ø¹Øªâ€ŒØ¨Ø®Ø´ âš¡',
                'description': '10 Ø§Ù†ØªÙ‚Ø§Ù„ Ù…ØªÙˆØ§Ù„ÛŒ Ø¨Ø§ Ø³Ø±Ø¹Øª Ø¨ÛŒØ´ Ø§Ø² 10MB/s',
                'condition': lambda stats: stats.get('high_speed_streak', 0) >= 10,
                'xp_reward': 250,
                'icon': 'âš¡'
            },
            {
                'id': 'efficient',
                'name': 'Ú©Ø§Ø±Ø¢Ù…Ø¯ â™»ï¸',
                'description': 'Ú©Ø§Ø±Ø§ÛŒÛŒ Ø¨ÛŒØ´ Ø§Ø² 90% Ø¯Ø± 5 Ø§Ù†ØªÙ‚Ø§Ù„ Ù…ØªÙˆØ§Ù„ÛŒ',
                'condition': lambda stats: stats.get('high_efficiency_streak', 0) >= 5,
                'xp_reward': 180,
                'icon': 'â™»ï¸'
            }
        ]
    
    def _load_levels(self) -> List[Dict]:
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø³Ø·ÙˆØ­"""
        return [
            {'level': 1, 'xp_required': 0, 'title': 'ØªØ§Ø²Ù‡â€ŒÚ©Ø§Ø±'},
            {'level': 2, 'xp_required': 100, 'title': 'Ú©Ø§Ø±Ø¢Ù…ÙˆØ²'},
            {'level': 3, 'xp_required': 300, 'title': 'Ú©Ø§Ø±Ø¨Ø±'},
            {'level': 4, 'xp_required': 600, 'title': 'Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ'},
            {'level': 5, 'xp_required': 1000, 'title': 'Ù…ØªØ®ØµØµ'},
            {'level': 6, 'xp_required': 1500, 'title': 'Ø§Ø³ØªØ§Ø¯'},
            {'level': 7, 'xp_required': 2100, 'title': 'Ú†ÛŒØ±Ù‡â€ŒØ¯Ø³Øª'},
            {'level': 8, 'xp_required': 2800, 'title': 'Ø§Ø³Ø·ÙˆØ±Ù‡'},
            {'level': 9, 'xp_required': 3600, 'title': 'Ø§ÙØ³Ø§Ù†Ù‡'},
            {'level': 10, 'xp_required': 4500, 'title': 'Ø¨Ø§ÙˆØ±Ù†Ú©Ø±Ø¯Ù†ÛŒ'}
        ]
    
    def update_stats(self, transfer_data: Dict) -> Dict:
        """Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¢Ù…Ø§Ø± Ú©Ø§Ø±Ø¨Ø±"""
        # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø²Ù…Ø§Ù† Ø¢Ø®Ø±ÛŒÙ† ÙØ¹Ø§Ù„ÛŒØª
        now = time.time()
        last_activity = self.user_stats['last_activity']
        
        # Ø¨Ø±Ø±Ø³ÛŒ streak
        if now - last_activity > 48 * 3600:  # Ø¨ÛŒØ´ Ø§Ø² 48 Ø³Ø§Ø¹Øª
            self.user_stats['streak_days'] = 1
        elif now - last_activity > 24 * 3600:  # Ø¨ÛŒØ´ Ø§Ø² 24 Ø³Ø§Ø¹Øª
            self.user_stats['streak_days'] += 1
        
        self.user_stats['last_activity'] = now
        
        # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¢Ù…Ø§Ø± Ù¾Ø§ÛŒÙ‡
        self.user_stats['total_transfers'] += 1
        self.user_stats['total_data'] += transfer_data.get('size', 0)
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ XP
        xp_gained = self._calculate_xp(transfer_data)
        self.user_stats['xp'] += xp_gained
        self.user_stats['total_xp'] += xp_gained
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø³ØªØ§ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯
        new_achievements = []
        for achievement in self.achievements_db:
            if achievement['id'] not in self.user_stats['achievements']:
                if achievement['condition'](transfer_data):
                    self.user_stats['achievements'].append(achievement['id'])
                    self.user_stats['xp'] += achievement['xp_reward']
                    self.user_stats['total_xp'] += achievement['xp_reward']
                    
                    new_achievements.append({
                        'id': achievement['id'],
                        'name': achievement['name'],
                        'description': achievement['description'],
                        'xp_reward': achievement['xp_reward'],
                        'icon': achievement['icon']
                    })
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø§Ø±ØªÙ‚Ø§ Ø³Ø·Ø­
        old_level = self.user_stats['level']
        new_level = self._calculate_level(self.user_stats['xp'])
        
        level_up_message = None
        if new_level > old_level:
            self.user_stats['level'] = new_level
            level_up_message = self._create_level_up_message(old_level, new_level)
        
        return {
            'new_achievements': new_achievements,
            'xp_gained': xp_gained,
            'level_up': level_up_message,
            'current_level': new_level,
            'current_xp': self.user_stats['xp'],
            'xp_to_next_level': self._xp_to_next_level(new_level, self.user_stats['xp']),
            'total_achievements': len(self.user_stats['achievements'])
        }
    
    def _calculate_xp(self, transfer_data: Dict) -> int:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ XP Ú©Ø³Ø¨ Ø´Ø¯Ù‡"""
        base_xp = 10
        
        # Ù¾Ø§Ø¯Ø§Ø´ Ø³Ø±Ø¹Øª
        speed_bonus = min(50, transfer_data.get('avg_speed', 0) / (1024 * 1024))  # 1MB/s = 1 XP
        
        # Ù¾Ø§Ø¯Ø§Ø´ Ø­Ø¬Ù…
        size_bonus = min(100, transfer_data.get('size', 0) / (100 * 1024 * 1024))  # 100MB = 1 XP
        
        # Ù¾Ø§Ø¯Ø§Ø´ Ú©Ø§Ø±Ø§ÛŒÛŒ
        efficiency_bonus = 0
        if transfer_data.get('efficiency_score', 0) > 90:
            efficiency_bonus = 30
        elif transfer_data.get('efficiency_score', 0) > 70:
            efficiency_bonus = 15
        
        # Ø¬Ø±ÛŒÙ…Ù‡ Ø®Ø·Ø§
        error_penalty = transfer_data.get('error_count', 0) * 5
        
        # Ù¾Ø§Ø¯Ø§Ø´ streak
        streak_bonus = min(self.user_stats['streak_days'] * 2, 20)
        
        total_xp = base_xp + speed_bonus + size_bonus + efficiency_bonus + streak_bonus - error_penalty
        
        return max(1, int(total_xp))
    
    def _calculate_level(self, xp: int) -> int:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø³Ø·Ø­ Ø¨Ø± Ø§Ø³Ø§Ø³ XP"""
        for level_info in reversed(self.levels_db):
            if xp >= level_info['xp_required']:
                return level_info['level']
        return 1
    
    def _xp_to_next_level(self, current_level: int, current_xp: int) -> int:
        """XP Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Ø¨Ø±Ø§ÛŒ Ø³Ø·Ø­ Ø¨Ø¹Ø¯ÛŒ"""
        if current_level >= len(self.levels_db):
            return 0
        
        next_level_xp = self.levels_db[current_level]['xp_required']
        return max(0, next_level_xp - current_xp)
    
    def _create_level_up_message(self, old_level: int, new_level: int) -> str:
        """Ø§ÛŒØ¬Ø§Ø¯ Ù¾ÛŒØ§Ù… Ø§Ø±ØªÙ‚Ø§ Ø³Ø·Ø­"""
        old_title = self.levels_db[old_level - 1]['title']
        new_title = self.levels_db[new_level - 1]['title']
        
        celebrations = ['ğŸ‰', 'ğŸŠ', 'ğŸ¥³', 'ğŸˆ', 'ğŸ‘‘', 'ğŸ†', 'â­', 'âœ¨']
        celebration = random.choice(celebrations)
        
        return f"{celebration} ØªØ¨Ø±ÛŒÚ©! Ø´Ù…Ø§ Ø§Ø² Ø³Ø·Ø­ {old_level} ({old_title}) " \
               f"Ø¨Ù‡ Ø³Ø·Ø­ {new_level} ({new_title}) Ø§Ø±ØªÙ‚Ø§ ÛŒØ§ÙØªÛŒØ¯! {celebration}"
    
    def create_profile_card(self) -> str:
        """Ø§ÛŒØ¬Ø§Ø¯ Ú©Ø§Ø±Øª Ù¾Ø±ÙˆÙØ§ÛŒÙ„ Ú©Ø§Ø±Ø¨Ø±"""
        ui = ProgressUI()
        current_level_info = self.levels_db[self.user_stats['level'] - 1]
        next_level_info = self.levels_db[self.user_stats['level']] if \
                         self.user_stats['level'] < len(self.levels_db) else None
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù¾ÛŒØ´Ø±ÙØª Ø³Ø·Ø­
        level_progress = 0
        if next_level_info:
            current_level_xp = current_level_info['xp_required']
            next_level_xp = next_level_info['xp_required']
            level_range = next_level_xp - current_level_xp
            xp_in_level = self.user_stats['xp'] - current_level_xp
            level_progress = (xp_in_level / level_range * 100) if level_range > 0 else 100
        
        lines = []
        lines.append(f"{ui.COLORS['bold']}ğŸ® Ù¾Ø±ÙˆÙØ§ÛŒÙ„ Ú©Ø§Ø±Ø¨Ø±ÛŒ{ui.COLORS['reset']}")
        lines.append("=" * 40)
        
        # Ø³Ø·Ø­ Ùˆ XP
        lines.append(f"ğŸ“Š Ø³Ø·Ø­: {self.user_stats['level']} - {current_level_info['title']}")
        
        if next_level_info:
            progress_bar = ui.create_progress_bar(level_progress, 20)
            lines.append(f"   {progress_bar} {level_progress:.1f}%")
            lines.append(f"   XP: {self.user_stats['xp']:,} / {next_level_info['xp_required']:,}")
        else:
            lines.append(f"   ğŸ† Ø´Ù…Ø§ Ø¨Ù‡ Ø­Ø¯Ø§Ú©Ø«Ø± Ø³Ø·Ø­ Ø±Ø³ÛŒØ¯Ù‡â€ŒØ§ÛŒØ¯!")
            lines.append(f"   XP Ú©Ù„: {self.user_stats['xp']:,}")
        
        lines.append("")
        
        # Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ
        lines.append(f"ğŸ“ˆ Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ:")
        lines.append(f"   â”œâ”€ Ø§Ù†ØªÙ‚Ø§Ù„â€ŒÙ‡Ø§: {self.user_stats['total_transfers']:,}")
        lines.append(f"   â”œâ”€ Ø­Ø¬Ù… Ú©Ù„: {ui.format_size(self.user_stats['total_data'])}")
        lines.append(f"   â”œâ”€ Ø¯Ø³ØªØ§ÙˆØ±Ø¯Ù‡Ø§: {len(self.user_stats['achievements'])}/{len(self.achievements_db)}")
        lines.append(f"   â””â”€ Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù…ØªÙˆØ§Ù„ÛŒ: {self.user_stats['streak_days']}")
        
        lines.append("")
        
        # Ø¯Ø³ØªØ§ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ø§Ø®ÛŒØ±
        if self.user_stats['achievements']:
            recent_achievements = self.user_stats['achievements'][-3:]
            lines.append(f"ğŸ… Ø¯Ø³ØªØ§ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ø§Ø®ÛŒØ±:")
            for achievement_id in recent_achievements:
                achievement = next((a for a in self.achievements_db 
                                  if a['id'] == achievement_id), None)
                if achievement:
                    lines.append(f"   {achievement['icon']} {achievement['name']}")
        
        # Ø¬Ù„Ø³Ù‡ ÙØ¹Ù„ÛŒ
        session_duration = time.time() - self.user_stats['session_start']
        if session_duration > 60:
            lines.append("")
            lines.append(f"â±ï¸ Ø²Ù…Ø§Ù† Ø¬Ù„Ø³Ù‡: {ui.format_time(session_duration)}")
        
        return "\n".join(lines)

# ================ External Integration ================

class ExternalIntegration:
    """ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø§ Ø³Ø±ÙˆÛŒØ³â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ø±Ø¬ÛŒ"""
    
    @staticmethod
    def export_to_prometheus(metrics: Dict, job_name: str = "file_transfer") -> str:
        """Ø®Ø±ÙˆØ¬ÛŒ ÙØ±Ù…Øª Prometheus"""
        prometheus_lines = []
        
        # HELP Ùˆ TYPE
        prometheus_lines.append(f'# HELP transfer_speed_bytes File transfer speed in bytes per second')
        prometheus_lines.append(f'# TYPE transfer_speed_bytes gauge')
        prometheus_lines.append(f'transfer_speed_bytes{{job="{job_name}"}} {metrics.get("speed", 0)}')
        
        prometheus_lines.append(f'# HELP transfer_percent File transfer percentage')
        prometheus_lines.append(f'# TYPE transfer_percent gauge')
        prometheus_lines.append(f'transfer_percent{{job="{job_name}"}} {metrics.get("percent", 0)}')
        
        prometheus_lines.append(f'# HELP transfer_remaining_bytes Remaining bytes to transfer')
        prometheus_lines.append(f'# TYPE transfer_remaining_bytes gauge')
        remaining = metrics.get('total', 0) - metrics.get('transferred', 0)
        prometheus_lines.append(f'transfer_remaining_bytes{{job="{job_name}"}} {remaining}')
        
        prometheus_lines.append(f'# HELP transfer_elapsed_seconds Elapsed time in seconds')
        prometheus_lines.append(f'# TYPE transfer_elapsed_seconds gauge')
        prometheus_lines.append(f'transfer_elapsed_seconds{{job="{job_name}"}} {metrics.get("elapsed", 0)}')
        
        prometheus_lines.append(f'# HELP transfer_errors_total Total number of errors')
        prometheus_lines.append(f'# TYPE transfer_errors_total counter')
        prometheus_lines.append(f'transfer_errors_total{{job="{job_name}"}} {metrics.get("error_count", 0)}')
        
        return '\n'.join(prometheus_lines)
    
    @staticmethod
    def export_to_json(metrics: Dict, pretty: bool = True) -> str:
        """Ø®Ø±ÙˆØ¬ÛŒ JSON"""
        export_data = {
            'timestamp': time.time(),
            'timestamp_iso': datetime.now().isoformat(),
            'metrics': {
                'transferred': metrics.get('transferred', 0),
                'total': metrics.get('total', 0),
                'percent': metrics.get('percent', 0),
                'speed': metrics.get('speed', 0),
                'elapsed': metrics.get('elapsed', 0),
                'remaining': metrics.get('remaining', 0),
                'error_count': metrics.get('error_count', 0)
            },
            'formatting': {
                'transferred_fmt': ProgressUI.format_size(metrics.get('transferred', 0)),
                'total_fmt': ProgressUI.format_size(metrics.get('total', 0)),
                'speed_fmt': ProgressUI.format_speed(metrics.get('speed', 0)),
                'elapsed_fmt': ProgressUI.format_time(metrics.get('elapsed', 0)),
                'remaining_fmt': ProgressUI.format_time(metrics.get('remaining', 0))
            },
            'metadata': {
                'version': '1.0.0',
                'exported_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
        }
        
        if pretty:
            return json.dumps(export_data, indent=2, ensure_ascii=False)
        else:
            return json.dumps(export_data, ensure_ascii=False)
    
    @staticmethod
    def create_grafana_dashboard_config(metrics_list: List[str]) -> Dict:
        """Ø§ÛŒØ¬Ø§Ø¯ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Grafana"""
        panels = []
        
        # Ù¾Ù†Ù„ Ø³Ø±Ø¹Øª
        if 'transfer_speed' in metrics_list:
            panels.append({
                'title': 'Transfer Speed',
                'type': 'graph',
                'gridPos': {'h': 8, 'w': 12, 'x': 0, 'y': 0},
                'targets': [
                    {
                        'expr': 'rate(transfer_speed_bytes[5m])',
                        'legendFormat': 'Speed',
                        'refId': 'A'
                    }
                ]
            })
        
        # Ù¾Ù†Ù„ Ù¾ÛŒØ´Ø±ÙØª
        if 'transfer_percent' in metrics_list:
            panels.append({
                'title': 'Transfer Progress',
                'type': 'stat',
                'gridPos': {'h': 4, 'w': 6, 'x': 0, 'y': 8},
                'targets': [
                    {
                        'expr': 'transfer_percent',
                        'legendFormat': 'Progress',
                        'refId': 'A'
                    }
                ],
                'fieldConfig': {
                    'defaults': {
                        'unit': 'percent',
                        'min': 0,
                        'max': 100
                    }
                }
            })
        
        # Ù¾Ù†Ù„ Ø®Ø·Ø§Ù‡Ø§
        if 'transfer_errors' in metrics_list:
            panels.append({
                'title': 'Transfer Errors',
                'type': 'stat',
                'gridPos': {'h': 4, 'w': 6, 'x': 6, 'y': 8},
                'targets': [
                    {
                        'expr': 'increase(transfer_errors_total[5m])',
                        'legendFormat': 'Errors',
                        'refId': 'A'
                    }
                ],
                'fieldConfig': {
                    'defaults': {
                        'color': {'mode': 'thresholds'},
                        'thresholds': {
                            'steps': [
                                {'color': 'green', 'value': None},
                                {'color': 'red', 'value': 1}
                            ]
                        }
                    }
                }
            })
        
        return {
            'dashboard': {
                'title': 'File Transfer Monitor',
                'panels': panels,
                'time': {'from': 'now-1h', 'to': 'now'},
                'refresh': '5s'
            },
            'overwrite': True
        }
    
    @staticmethod
    def send_to_webhook(data: Dict, webhook_url: str, 
                       format: str = 'json') -> bool:
        """Ø§Ø±Ø³Ø§Ù„ Ø¯Ø§Ø¯Ù‡ Ø¨Ù‡ ÙˆØ¨â€ŒÙ‡ÙˆÚ©"""
        try:
            import requests
            
            headers = {'Content-Type': 'application/json'}
            
            if format == 'prometheus':
                payload = ExternalIntegration.export_to_prometheus(data)
                headers['Content-Type'] = 'text/plain'
            else:
                payload = ExternalIntegration.export_to_json(data, False)
            
            response = requests.post(webhook_url, data=payload, headers=headers, timeout=10)
            return response.status_code == 200
            
        except Exception as e:
            print(f"Error sending to webhook: {e}")
            return False

# ================ Advanced Visualization ================

class AdvancedVisualization:
    """ÙˆÛŒÚ˜ÙˆØ§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø§ ASCII Art"""
    
    @staticmethod
    def create_speed_heatmap(speed_data: List[List[float]], 
                           width: int = 50, height: int = 10) -> str:
        """Ø§ÛŒØ¬Ø§Ø¯ Ù‡ÛŒØªâ€ŒÙ…Ù¾ Ø³Ø±Ø¹Øª"""
        if not speed_data or not speed_data[0]:
            return "ğŸ”¥ (Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª)"
        
        # Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø¹Ø±Ø¶
        data_width = min(width, len(speed_data[0]))
        data = [row[:data_width] for row in speed_data[:height]]
        
        # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† max Ú©Ù„ÛŒ
        max_val = max(max(row) for row in data) if data else 1
        
        # Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ Ú¯Ø±Ø§Ø¯ÛŒØ§Ù†
        gradient = " â–‘â–’â–“â–ˆ"
        
        # Ø§ÛŒØ¬Ø§Ø¯ Ù‡ÛŒØªâ€ŒÙ…Ù¾
        heatmap = []
        for row in data:
            heat_row = []
            for val in row:
                # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ùˆ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ø§Ø±Ø§Ú©ØªØ±
                if max_val > 0:
                    level = int((val / max_val) * (len(gradient) - 1))
                    level = max(0, min(len(gradient) - 1, level))
                else:
                    level = 0
                heat_row.append(gradient[level])
            heatmap.append(''.join(heat_row))
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† legend
        legend = f"â†•ï¸ 0 - {ProgressUI.format_speed(max_val)}"
        heatmap.append('â”€' * data_width)
        heatmap.append(legend)
        
        return '\n'.join(heatmap)
    
    @staticmethod
    def create_network_topology(nodes: List[Dict], connections: List[Tuple[str, str]]) -> str:
        """Ù†Ù…Ø§ÛŒØ´ ØªÙˆÙ¾ÙˆÙ„ÙˆÚ˜ÛŒ Ø´Ø¨Ú©Ù‡"""
        topology_lines = []
        
        topology_lines.append("ğŸŒ **ØªÙˆÙ¾ÙˆÙ„ÙˆÚ˜ÛŒ Ø´Ø¨Ú©Ù‡**")
        topology_lines.append("")
        
        # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø±ÛŒØ´Ù‡ (Ø³Ø±ÙˆØ± Ø§ØµÙ„ÛŒ)
        root_nodes = [node for node in nodes if node.get('type') == 'server']
        
        if root_nodes:
            root = root_nodes[0]
            topology_lines.append(f"    [{root['name']}]")
            topology_lines.append("        â”‚")
        
        # Ù†Ù…Ø§ÛŒØ´ Ø§ØªØµØ§Ù„Ø§Øª
        for i, (source, target) in enumerate(connections):
            if i == len(connections) - 1:
                prefix = "        â””â”€â”€"
            else:
                prefix = "        â”œâ”€â”€"
            
            target_node = next((n for n in nodes if n['id'] == target), None)
            if target_node:
                topology_lines.append(f"{prefix} [{target_node['name']}]")
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¢Ù…Ø§Ø±
        topology_lines.append("")
        topology_lines.append(f"ğŸ“Š Ø¢Ù…Ø§Ø±:")
        topology_lines.append(f"  â€¢ Ú¯Ø±Ù‡â€ŒÙ‡Ø§: {len(nodes)}")
        topology_lines.append(f"  â€¢ Ø§ØªØµØ§Ù„Ø§Øª: {len(connections)}")
        
        return '\n'.join(topology_lines)
    
    @staticmethod
    def create_radial_progress(percent: float, radius: int = 5) -> str:
        """Ø§ÛŒØ¬Ø§Ø¯ Ù¾ÛŒØ´Ø±ÙØª Ø´Ø¹Ø§Ø¹ÛŒ"""
        if percent < 0:
            percent = 0
        elif percent > 100:
            percent = 100
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø²Ø§ÙˆÛŒÙ‡
        angle = 360 * percent / 100
        
        # Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ Ø¯Ø§ÛŒØ±Ù‡
        circle_chars = " .'`^\",:;Il!i><~+_-?][}{1)(|\\/tfjrxnuvczXYUJCLQ0OZmwqpdbkhao*#MW&8%B@$"
        
        lines = []
        for y in range(-radius, radius + 1):
            line = []
            for x in range(-radius, radius + 1):
                # Ù…Ø­Ø§Ø³Ø¨Ù‡ ÙØ§ØµÙ„Ù‡ Ø§Ø² Ù…Ø±Ú©Ø²
                distance = math.sqrt(x * x + y * y)
                
                if distance <= radius:
                    # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø²Ø§ÙˆÛŒÙ‡
                    point_angle = math.degrees(math.atan2(y, x))
                    if point_angle < 0:
                        point_angle += 360
                    
                    # Ø¨Ø±Ø±Ø³ÛŒ Ø¢ÛŒØ§ Ù†Ù‚Ø·Ù‡ Ø¯Ø§Ø®Ù„ Ø¨Ø®Ø´ Ù¾Ø± Ø´Ø¯Ù‡ Ø§Ø³Øª
                    if point_angle <= angle:
                        # Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ø§Ø±Ø§Ú©ØªØ± Ø¨Ø± Ø§Ø³Ø§Ø³ ÙØ§ØµÙ„Ù‡
                        char_index = int((distance / radius) * (len(circle_chars) - 1))
                        line.append(circle_chars[char_index])
                    else:
                        line.append(' ')
                else:
                    line.append(' ')
            
            lines.append(''.join(line))
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¯Ø±ØµØ¯ Ø¯Ø± Ù…Ø±Ú©Ø²
        center_line = lines[radius]
        percent_str = f"{percent:.0f}%"
        start = (len(center_line) - len(percent_str)) // 2
        lines[radius] = center_line[:start] + percent_str + center_line[start + len(percent_str):]
        
        return '\n'.join(lines)

# ================ Main Application ================

class ProgressManager:
    """Ù…Ø¯ÛŒØ± Ø§ØµÙ„ÛŒ Ù¾ÛŒØ´Ø±ÙØª"""
    
    def __init__(self, config: Optional[ProgressConfig] = None):
        self.ui = ProgressUI(config)
        self.ai_predictor = AIPredictionProgress(self.ui)
        self.multi_file = MultiFileProgress(self.ui)
        self.optimizer = AdaptiveTransferOptimizer()
        self.analytics = RealTimeAnalytics()
        self.gamification = GamificationEngine()
        self.visualization = AdvancedVisualization()
        
        self.current_transfer = None
        self.is_running = False
        self.last_display_time = 0
        self.display_interval = 0.1  # Ø«Ø§Ù†ÛŒÙ‡
        
    def start_transfer(self, filename: str, size: int, 
                      transfer_type: str = "download") -> str:
        """Ø´Ø±ÙˆØ¹ ÛŒÚ© Ø§Ù†ØªÙ‚Ø§Ù„ Ø¬Ø¯ÛŒØ¯"""
        transfer_id = hashlib.md5(f"{filename}{time.time()}".encode()).hexdigest()[:8]
        
        self.current_transfer = {
            'id': transfer_id,
            'filename': filename,
            'size': size,
            'type': transfer_type,
            'start_time': time.time(),
            'metrics': TransferMetrics(total=size),
            'status': TransferStatus.TRANSFERRING,
            'chunks': [],
            'optimization': None
        }
        
        # ØªØ­Ù„ÛŒÙ„ Ø´Ø¨Ú©Ù‡ Ø§ÙˆÙ„ÛŒÙ‡
        self.current_transfer['optimization'] = self.optimizer.analyze_network(
            [], [], 0.0
        )
        
        # Ø´Ø±ÙˆØ¹ Ø¢Ù†Ø§Ù„ÛŒØªÛŒÚ©Ø³
        self.analytics.track_metric('transfer_started', 1, {
            'filename': filename,
            'size': size,
            'type': transfer_type
        })
        
        self.is_running = True
        
        return transfer_id
    
    def update_transfer(self, transferred: int, speed: Optional[float] = None,
                       latency: Optional[float] = None, errors: int = 0):
        """Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø§Ù†ØªÙ‚Ø§Ù„"""
        if not self.current_transfer or not self.is_running:
            return
        
        metrics = self.current_transfer['metrics']
        
        # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§
        old_transferred = metrics.transferred
        metrics.transferred = transferred
        
        if speed is not None:
            metrics.speed = speed
            metrics.speed_history.append(speed)
        
        metrics.elapsed = time.time() - self.current_transfer['start_time']
        metrics.error_count = errors
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø²Ù…Ø§Ù† Ø¨Ø§Ù‚ÛŒÙ…Ø§Ù†Ø¯Ù‡
        if speed and speed > 0:
            remaining = (metrics.total - transferred) / speed
            metrics.remaining = remaining
        
        # Ø±Ø¯ÛŒØ§Ø¨ÛŒ Ø¢Ù†Ø§Ù„ÛŒØªÛŒÚ©Ø³
        self.analytics.track_metric('transfer_speed', speed or 0)
        self.analytics.track_metric('transfer_progress', metrics.percent)
        
        if latency:
            self.analytics.track_metric('latency', latency)
        
        # Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù¾ÙˆÛŒØ§ (Ù‡Ø± 5 Ø«Ø§Ù†ÛŒÙ‡)
        current_time = time.time()
        if current_time - self.last_display_time > 5:
            self._optimize_transfer()
            self.last_display_time = current_time
        
        # Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ´Ø±ÙØª (Ø¨Ø§ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ù†Ø±Ø®)
        if current_time - self.last_display_time >= self.display_interval:
            self.display_progress()
            self.last_display_time = current_time
        
        # Ø¨Ø±Ø±Ø³ÛŒ ØªÚ©Ù…ÛŒÙ„
        if transferred >= metrics.total:
            self.complete_transfer()
    
    def _optimize_transfer(self):
        """Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø§Ù†ØªÙ‚Ø§Ù„"""
        if not self.current_transfer:
            return
        
        metrics = self.current_transfer['metrics']
        
        # ØªØ­Ù„ÛŒÙ„ Ø´Ø¨Ú©Ù‡
        optimization = self.optimizer.analyze_network(
            metrics.speed_history[-20:] if len(metrics.speed_history) >= 20 else metrics.speed_history,
            [100],  # ØªØ£Ø®ÛŒØ± Ù†Ù…ÙˆÙ†Ù‡
            metrics.error_count / max(1, len(metrics.speed_history))
        )
        
        self.current_transfer['optimization'] = optimization
        
        # Ø±Ø¯ÛŒØ§Ø¨ÛŒ Ø¨Ø±Ø§ÛŒ Ø¢Ù†Ø§Ù„ÛŒØªÛŒÚ©Ø³
        self.analytics.track_metric('network_quality', optimization['quality_score'])
        self.analytics.track_metric('chunk_size', optimization['optimal_chunk_size'])
    
    def display_progress(self, detailed: bool = True):
        """Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ´Ø±ÙØª"""
        if not self.current_transfer:
            return
        
        metrics = self.current_transfer['metrics']
        
        if detailed:
            # Ù†Ù…Ø§ÛŒØ´ Ø¨Ø§ Ø¬Ø²Ø¦ÛŒØ§Øª
            progress_text = self.ui.create_detailed_progress(metrics, show_graph=True)
            
            # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯
            if len(metrics.speed_history) > 10:
                prediction = self.ai_predictor.predict_completion(metrics)
                
                if prediction['confidence'] > 0.5:
                    remaining_fmt = self.ui.format_time(prediction['remaining_time'])
                    confidence_pct = prediction['confidence'] * 100
                    
                    prediction_text = (
                        f"\nğŸ¤– Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ (Ø§Ø¹ØªÙ…Ø§Ø¯: {confidence_pct:.0f}%):\n"
                        f"   â³ Ø¨Ø§Ù‚ÛŒÙ…Ø§Ù†Ø¯Ù‡: {remaining_fmt}\n"
                        f"   ğŸ“Š Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§:\n"
                        f"      â€¢ Ø¨Ù‡ØªØ±ÛŒÙ† Ø­Ø§Ù„Øª: {self.ui.format_time(prediction['scenarios']['best_case'])}\n"
                        f"      â€¢ Ø­Ø§Ù„Øª Ù…Ø­ØªÙ…Ù„: {self.ui.format_time(prediction['scenarios']['likely_case'])}\n"
                        f"      â€¢ Ø¨Ø¯ØªØ±ÛŒÙ† Ø­Ø§Ù„Øª: {self.ui.format_time(prediction['scenarios']['worst_case'])}"
                    )
                    
                    progress_text += prediction_text
            
            # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ
            if self.current_transfer['optimization']:
                optimization_text = (
                    f"\nğŸ”§ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¨Ú©Ù‡:\n"
                    f"   Chunk Size: {self.ui.format_size(self.current_transfer['optimization']['optimal_chunk_size'])}\n"
                    f"   Ú©ÛŒÙÛŒØª: {self.current_transfer['optimization']['network_quality'].value} "
                    f"({self.current_transfer['optimization']['quality_score']:.1f}/100)"
                )
                
                progress_text += optimization_text
            
            print("\033[2J\033[H")  # Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† ØªØ±Ù…ÛŒÙ†Ø§Ù„
            print(progress_text)
        else:
            # Ù†Ù…Ø§ÛŒØ´ Ù…ÛŒÙ†ÛŒØ§ØªÙˆØ±ÛŒ
            mini_text = self.ui.create_mini_progress(metrics)
            print(f"\r{mini_text}", end="", flush=True)
    
    def complete_transfer(self):
        """ØªÚ©Ù…ÛŒÙ„ Ø§Ù†ØªÙ‚Ø§Ù„"""
        if not self.current_transfer:
            return
        
        metrics = self.current_transfer['metrics']
        metrics.end_time = time.time()
        self.current_transfer['status'] = TransferStatus.COMPLETED
        self.is_running = False
        
        # Ø§ÛŒØ¬Ø§Ø¯ Ø®Ù„Ø§ØµÙ‡
        summary = self.ui.create_transfer_summary(
            metrics,
            self.current_transfer['type'],
            self.current_transfer['filename']
        )
        
        # Ú¯Ø²Ø§Ø±Ø´ Ø¢Ù†Ø§Ù„ÛŒØªÛŒÚ©Ø³
        report = self.analytics.generate_performance_report(5)
        analytics_dashboard = self.analytics.create_analytics_dashboard(report)
        
        # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ú¯ÛŒÙ…ÛŒÙÛŒÚ©ÛŒØ´Ù†
        transfer_data = {
            'size': metrics.total,
            'avg_speed': metrics.avg_speed,
            'max_speed': metrics.max_speed,
            'error_count': metrics.error_count,
            'efficiency_score': report.get('efficiency_score', 50),
            'completed_at_hour': datetime.now().hour
        }
        
        gamification_update = self.gamification.update_stats(transfer_data)
        profile_card = self.gamification.create_profile_card()
        
        # Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬
        print("\033[2J\033[H")  # Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† ØªØ±Ù…ÛŒÙ†Ø§Ù„
        print(summary)
        print("\n" + "="*60 + "\n")
        print(analytics_dashboard)
        print("\n" + "="*60 + "\n")
        print(profile_card)
        
        # Ù†Ù…Ø§ÛŒØ´ Ø¯Ø³ØªØ§ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯
        if gamification_update['new_achievements']:
            print("\nğŸ† Ø¯Ø³ØªØ§ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯:")
            for achievement in gamification_update['new_achievements']:
                print(f"   {achievement['icon']} {achievement['name']} (+{achievement['xp_reward']} XP)")
        
        if gamification_update['level_up']:
            print(f"\n{gamification_update['level_up']}")
        
        # Ø±Ø¯ÛŒØ§Ø¨ÛŒ ØªÚ©Ù…ÛŒÙ„
        self.analytics.track_metric('transfer_completed', 1, {
            'filename': self.current_transfer['filename'],
            'size': metrics.total,
            'duration': metrics.elapsed,
            'avg_speed': metrics.avg_speed
        })
    
    def add_multiple_files(self, files: List[Tuple[str, int]]):
        """Ø§ÙØ²ÙˆØ¯Ù† Ú†Ù†Ø¯ÛŒÙ† ÙØ§ÛŒÙ„"""
        for i, (filename, size) in enumerate(files):
            file_id = f"file_{i}_{int(time.time())}"
            self.multi_file.add_file(file_id, filename, size, priority=len(files)-i)
    
    def display_multi_file_dashboard(self):
        """Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ú†Ù†Ø¯ ÙØ§ÛŒÙ„ÛŒ"""
        if not self.multi_file.files:
            print("Ù‡ÛŒÚ† ÙØ§ÛŒÙ„ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")
            return
        
        dashboard = self.multi_file.create_dashboard(show_details=True)
        print("\033[2J\033[H")  # Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† ØªØ±Ù…ÛŒÙ†Ø§Ù„
        print(dashboard)
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
        stats = self.multi_file.get_file_stats()
        if stats['average_speed'] > 0:
            remaining = stats['total_size'] - stats['transferred_size']
            eta_seconds = remaining / stats['average_speed']
            
            print(f"\nâ³ ØªØ®Ù…ÛŒÙ† Ø²Ù…Ø§Ù† ØªÚ©Ù…ÛŒÙ„ Ù‡Ù…Ù‡ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§: {self.ui.format_time(eta_seconds)}")

# ================ Example Usage ================

def example_usage():
    """Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ Ù¾ÛŒØ´Ø±ÙØªÙ‡"""
    
    # Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø¯ÛŒØ± Ù¾ÛŒØ´Ø±ÙØª
    config = ProgressConfig(
        show_percentage=True,
        show_speed=True,
        show_time=True,
        show_graph=True,
        graph_width=40,
        graph_height=8,
        use_colors=True,
        show_eta=True,
        compact_mode=False
    )
    
    manager = ProgressManager(config)
    
    print("ğŸš€ Ø´Ø±ÙˆØ¹ Ø§Ù†ØªÙ‚Ø§Ù„ Ù¾ÛŒØ´Ø±ÙØªÙ‡")
    print("="*60)
    
    # Ø´Ø±ÙˆØ¹ ÛŒÚ© Ø§Ù†ØªÙ‚Ø§Ù„
    transfer_id = manager.start_transfer(
        filename="large_file.zip",
        size=500 * 1024 * 1024,  # 500MB
        transfer_type="download"
    )
    
    print(f"Ø´Ù†Ø§Ø³Ù‡ Ø§Ù†ØªÙ‚Ø§Ù„: {transfer_id}")
    print()
    
    # Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø§Ù†ØªÙ‚Ø§Ù„
    import random
    
    transferred = 0
    total_size = 500 * 1024 * 1024
    
    while transferred < total_size:
        # Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø³Ø±Ø¹Øª Ø¨Ø§ Ù†ÙˆØ³Ø§Ù†
        base_speed = 5 * 1024 * 1024  # 5MB/s
        speed_variation = random.uniform(0.8, 1.2)
        current_speed = base_speed * speed_variation
        
        # Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ chunk
        chunk_size = min(10 * 1024 * 1024, total_size - transferred)  # Ø­Ø¯Ø§Ú©Ø«Ø± 10MB
        transferred += chunk_size
        
        # Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ ØªØ£Ø®ÛŒØ±
        latency = random.uniform(50, 200)  # 50-200ms
        
        # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø§Ù†ØªÙ‚Ø§Ù„
        manager.update_transfer(
            transferred=transferred,
            speed=current_speed,
            latency=latency,
            errors=random.randint(0, 1) if random.random() < 0.05 else 0
        )
        
        # ØªØ£Ø®ÛŒØ± Ø¨Ø±Ø§ÛŒ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ
        time.sleep(0.5)
    
    print("\n" + "="*60)
    print("âœ… Ø§Ù†ØªÙ‚Ø§Ù„ ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯!")
    
    # Ù†Ù…ÙˆÙ†Ù‡â€ŒØ§ÛŒ Ø§Ø² Ú†Ù†Ø¯ ÙØ§ÛŒÙ„
    print("\n" + "="*60)
    print("ğŸ“ Ù…Ø¯ÛŒØ±ÛŒØª Ú†Ù†Ø¯ ÙØ§ÛŒÙ„")
    
    manager.add_multiple_files([
        ("file1.txt", 1024 * 1024),      # 1MB
        ("file2.jpg", 5 * 1024 * 1024),  # 5MB
        ("file3.zip", 50 * 1024 * 1024), # 50MB
        ("file4.mp4", 200 * 1024 * 1024) # 200MB
    ])
    
    # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù¾ÛŒØ´Ø±ÙØª ÙØ§ÛŒÙ„â€ŒÙ‡Ø§
    for i, (file_id, file_data) in enumerate(manager.multi_file.files.items()):
        progress = min(100, (i + 1) * 25)  # 25% Ù¾ÛŒØ´Ø±ÙØª Ø¨Ø±Ø§ÛŒ Ù‡Ø± ÙØ§ÛŒÙ„
        transferred = int(file_data['size'] * progress / 100)
        manager.multi_file.update_file_progress(file_id, transferred, speed=1024*1024)
    
    manager.display_multi_file_dashboard()
    
    # Ù†Ù…ÙˆÙ†Ù‡â€ŒØ§ÛŒ Ø§Ø² Ø¢Ù†Ø§Ù„ÛŒØªÛŒÚ©Ø³
    print("\n" + "="*60)
    print("ğŸ“Š Ú¯Ø²Ø§Ø±Ø´ Ø¢Ù†Ø§Ù„ÛŒØªÛŒÚ©Ø³")
    
    report = manager.analytics.generate_performance_report(1)  # 1 Ø¯Ù‚ÛŒÙ‚Ù‡ Ú¯Ø°Ø´ØªÙ‡
    dashboard = manager.analytics.create_analytics_dashboard(report)
    print(dashboard)
    
    # Ù†Ù…ÙˆÙ†Ù‡â€ŒØ§ÛŒ Ø§Ø² Ú¯ÛŒÙ…ÛŒÙÛŒÚ©ÛŒØ´Ù†
    print("\n" + "="*60)
    print("ğŸ® Ú¯ÛŒÙ…ÛŒÙÛŒÚ©ÛŒØ´Ù†")
    
    # Ú†Ù†Ø¯ Ø§Ù†ØªÙ‚Ø§Ù„ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡
    for i in range(5):
        transfer_data = {
            'size': random.randint(10, 100) * 1024 * 1024,
            'avg_speed': random.randint(1, 10) * 1024 * 1024,
            'max_speed': random.randint(5, 20) * 1024 * 1024,
            'error_count': random.randint(0, 2),
            'efficiency_score': random.randint(60, 95),
            'completed_at_hour': random.randint(0, 23)
        }
        
        result = manager.gamification.update_stats(transfer_data)
        
        if result['new_achievements']:
            print(f"Ø¯Ø³ØªØ§ÙˆØ±Ø¯ Ø¬Ø¯ÛŒØ¯: {result['new_achievements'][0]['name']}")
        
        if result['level_up']:
            print(result['level_up'])
    
    profile = manager.gamification.create_profile_card()
    print(profile)
    
    # Ù†Ù…ÙˆÙ†Ù‡â€ŒØ§ÛŒ Ø§Ø² export
    print("\n" + "="*60)
    print("ğŸ“¤ Export Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§")
    
    sample_metrics = {
        'transferred': 250 * 1024 * 1024,
        'total': 500 * 1024 * 1024,
        'speed': 5 * 1024 * 1024,
        'elapsed': 50,
        'remaining': 50,
        'error_count': 2
    }
    
    # Ø®Ø±ÙˆØ¬ÛŒ Prometheus
    prometheus_output = ExternalIntegration.export_to_prometheus(sample_metrics)
    print("ğŸ“Š Ø®Ø±ÙˆØ¬ÛŒ Prometheus:")
    print(prometheus_output[:200] + "...")
    
    # Ø®Ø±ÙˆØ¬ÛŒ JSON
    json_output = ExternalIntegration.export_to_json(sample_metrics, True)
    print("\nğŸ“„ Ø®Ø±ÙˆØ¬ÛŒ JSON:")
    print(json_output[:300] + "...")

if __name__ == "__main__":
    # Ù†Ù…Ø§ÛŒØ´ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù†Ø³Ø®Ù‡
    print(f"""
    ğŸš€ Progress UI Advanced - Ù†Ø³Ø®Ù‡ 2.0.0
    ğŸ“… {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
    
    ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ:
    â€¢ Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ´Ø±ÙØª Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø§ Ù†Ù…ÙˆØ¯Ø§Ø±
    â€¢ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø²Ù…Ø§Ù† ØªÚ©Ù…ÛŒÙ„
    â€¢ Ù…Ø¯ÛŒØ±ÛŒØª Ú†Ù†Ø¯ ÙØ§ÛŒÙ„ Ù‡Ù…Ø²Ù…Ø§Ù†
    â€¢ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù¾ÙˆÛŒØ§ Ø´Ø¨Ú©Ù‡
    â€¢ Ø¢Ù†Ø§Ù„ÛŒØªÛŒÚ©Ø³ Ù„Ø­Ø¸Ù‡â€ŒØ§ÛŒ
    â€¢ Ú¯ÛŒÙ…ÛŒÙÛŒÚ©ÛŒØ´Ù† Ùˆ Ø¯Ø³ØªØ§ÙˆØ±Ø¯Ù‡Ø§
    â€¢ ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø§ Ø³Ø±ÙˆÛŒØ³â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ø±Ø¬ÛŒ
    â€¢ ÙˆÛŒÚ˜ÙˆØ§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡
    
    """)
    
    # Ø§Ø¬Ø±Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡
    try:
        example_usage()
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ Ø®Ø±ÙˆØ¬ Ø§Ø² Ø¨Ø±Ù†Ø§Ù…Ù‡...")
    except Exception as e:
        print(f"\nâŒ Ø®Ø·Ø§: {e}")
        import traceback
        traceback.print_exc()
